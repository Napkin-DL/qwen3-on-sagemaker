{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Deployment and Inference using SageMaker Inference Component\n",
    "아래 모델 배포는 아래의 인스턴스에서 테스트 완료 되었습니다.\n",
    "- [Pricing Link](https://aws.amazon.com/sagemaker/pricing/)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting configuration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "registered_model : qwen3-4b\n",
      "compressed_model_path : s3://sagemaker-us-west-2-322537213286/checkpoint/Qwen/Qwen3-4B/compressed_model\n"
     ]
    }
   ],
   "source": [
    "print(f\"registered_model : {registered_model}\")\n",
    "print(f\"compressed_model_path : {compressed_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Getting inference container images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/pydantic/_internal/_fields.py:172: UserWarning: Field name \"json\" in \"MonitoringDatasetFormat\" shadows an attribute in parent \"Base\"\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:33:54] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:33:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=866510;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=422373;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:33:55] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:33:55]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=600389;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=92110;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=887159;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=108389;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=810173;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=645735;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker role arn: arn:aws:iam::322537213286:role/service-role/AmazonSageMaker-ExecutionRole-20250330T160497\n",
      "sagemaker session region: us-west-2\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_client = sess.sagemaker_client\n",
    "sagemaker_runtime_client = sess.sagemaker_runtime_client\n",
    "\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llm image uri: 763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.6.0-tgi3.2.3-gpu-py311-cu124-ubuntu22.04-v2.0\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import get_huggingface_llm_image_uri\n",
    "\n",
    "# # retrieve the llm image uri\n",
    "# llm_image = get_huggingface_llm_image_uri(\n",
    "#   \"huggingface\",\n",
    "#   session=sess,\n",
    "#   version=\"3.0.1\",\n",
    "# )\n",
    "\n",
    "llm_image=\"763104351884.dkr.ecr.us-west-2.amazonaws.com/huggingface-pytorch-tgi-inference:2.6.0-tgi3.2.3-gpu-py311-cu124-ubuntu22.04-v2.0\"\n",
    "\n",
    "# print ecr image uri\n",
    "print(f\"llm image uri: {llm_image}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating SageMaker Endpoint\n",
    "- Creating EndpointConfiguration\n",
    "- Creating Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml.g5.2xlarge and # of GPU 1 is set\n"
     ]
    }
   ],
   "source": [
    "instance_type = \"ml.g5.2xlarge\"\n",
    "# # instance_type = \"ml.g5.4xlarge\"\n",
    "# instance_type = \"ml.g5.xlarge\"\n",
    "\n",
    "\n",
    "if instance_type == \"ml.p4d.24xlarge\":\n",
    "    num_GPUSs = 8\n",
    "elif instance_type == \"ml.g5.12xlarge\":\n",
    "    num_GPUSs = 4\n",
    "elif instance_type == \"ml.g5.4xlarge\":\n",
    "    num_GPUSs = 1    \n",
    "else:\n",
    "    num_GPUSs = 1\n",
    "    \n",
    "print(f\"{instance_type} and # of GPU {num_GPUSs} is set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting the endpoint configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current time is 2025-05-05-02-33-56\n",
      "Endpoint config name: qwen3-4b-config-2025-05-05-02-33-56\n",
      "Initial instance count: 1\n",
      "Max instance count: 1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "currentTime = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "print(\"The current time is\", currentTime)\n",
    "\n",
    "# Set an unique endpoint config name\n",
    "endpoint_config_name = f\"{registered_model}-config-{currentTime}\" \n",
    "print(f\"Endpoint config name: {endpoint_config_name}\")\n",
    "\n",
    "\n",
    "# Set varient name and instance type for hosting\n",
    "variant_name = \"AllTraffic\"\n",
    "model_data_download_timeout_in_seconds = 600\n",
    "container_startup_health_check_timeout_in_seconds = 600\n",
    "\n",
    "initial_instance_count = 1\n",
    "max_instance_count = 1\n",
    "print(f\"Initial instance count: {initial_instance_count}\")\n",
    "print(f\"Max instance count: {max_instance_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating SageMaker Endpoint Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epc_response = sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ExecutionRoleArn=role,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"VariantName\": variant_name,\n",
    "            \"InstanceType\": instance_type,\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"ModelDataDownloadTimeoutInSeconds\": model_data_download_timeout_in_seconds,\n",
    "            \"ContainerStartupHealthCheckTimeoutInSeconds\": container_startup_health_check_timeout_in_seconds,\n",
    "            \"ManagedInstanceScaling\": {\n",
    "                \"Status\": \"ENABLED\",\n",
    "                \"MinInstanceCount\": initial_instance_count,\n",
    "                \"MaxInstanceCount\": max_instance_count,\n",
    "            },\n",
    "            \"RoutingConfig\": {\"RoutingStrategy\": \"LEAST_OUTSTANDING_REQUESTS\"},\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "from botocore.exceptions import ClientError, WaiterError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def create_and_wait_for_endpoint(sagemaker_client, sess, endpoint_name, endpoint_config_name, max_wait_time=3600, check_interval=30):\n",
    "    try:\n",
    "        # Create the endpoint\n",
    "        ep_response = sagemaker_client.create_endpoint(\n",
    "            EndpointName=endpoint_name,\n",
    "            EndpointConfigName=endpoint_config_name,\n",
    "        )\n",
    "        logging.info(f\"Creating endpoint: {endpoint_name}\")\n",
    "        \n",
    "        # Wait for the endpoint to be created\n",
    "        start_time = time.time()\n",
    "        while True:\n",
    "            try:\n",
    "                sess.wait_for_endpoint(endpoint_name, poll=check_interval)\n",
    "                logging.info(f\"Endpoint {endpoint_name} is now in service\")\n",
    "                break\n",
    "            except WaiterError as e:\n",
    "                if \"Max attempts exceeded\" in str(e):\n",
    "                    current_time = time.time()\n",
    "                    if current_time - start_time > max_wait_time:\n",
    "                        logging.error(f\"Endpoint creation timed out after {max_wait_time} seconds\")\n",
    "                        raise TimeoutError(f\"Endpoint creation timed out\")\n",
    "                    else:\n",
    "                        logging.info(\"Endpoint is still being created. Continuing to wait...\")\n",
    "                else:\n",
    "                    raise\n",
    "        \n",
    "        return ep_response\n",
    "    \n",
    "    except ClientError as e:\n",
    "        logging.error(f\"Error creating endpoint: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Unexpected error: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:33:56] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Endpoint name: qwen3-4b-endpoint-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>                   <a href=\"file:///tmp/ipykernel_88071/3371534808.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3371534808.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_88071/3371534808.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:33:56]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Endpoint name: qwen3-4b-endpoint-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m33\u001b[0m-\u001b[1;36m56\u001b[0m                   \u001b]8;id=593393;file:///tmp/ipykernel_88071/3371534808.py\u001b\\\u001b[2m3371534808.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=818671;file:///tmp/ipykernel_88071/3371534808.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating endpoint: qwen3-4b-endpoint-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>              <a href=\"file:///tmp/ipykernel_88071/2110020294.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2110020294.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_88071/2110020294.py#14\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating endpoint: qwen3-4b-endpoint-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m33\u001b[0m-\u001b[1;36m56\u001b[0m              \u001b]8;id=55730;file:///tmp/ipykernel_88071/2110020294.py\u001b\\\u001b[2m2110020294.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=739132;file:///tmp/ipykernel_88071/2110020294.py#14\u001b\\\u001b[2m14\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:37:27] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Endpoint qwen3-4b-endpoint-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span> is now in service      <a href=\"file:///tmp/ipykernel_88071/2110020294.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2110020294.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_88071/2110020294.py#21\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:37:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Endpoint qwen3-4b-endpoint-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m33\u001b[0m-\u001b[1;36m56\u001b[0m is now in service      \u001b]8;id=941351;file:///tmp/ipykernel_88071/2110020294.py\u001b\\\u001b[2m2110020294.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=406351;file:///tmp/ipykernel_88071/2110020294.py#21\u001b\\\u001b[2m21\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Endpoint created successfully                                          <a href=\"file:///tmp/ipykernel_88071/3371534808.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3371534808.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///tmp/ipykernel_88071/3371534808.py#7\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">7</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Endpoint created successfully                                          \u001b]8;id=358317;file:///tmp/ipykernel_88071/3371534808.py\u001b\\\u001b[2m3371534808.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=189306;file:///tmp/ipykernel_88071/3371534808.py#7\u001b\\\u001b[2m7\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Usage\n",
    "try:\n",
    "    endpoint_name = f\"{registered_model}-endpoint-{currentTime}\"\n",
    "    logging.info(f\"Endpoint name: {endpoint_name}\")\n",
    "    \n",
    "    ep_response = create_and_wait_for_endpoint(sagemaker_client, sess, endpoint_name, endpoint_config_name)\n",
    "    logging.info(\"Endpoint created successfully\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Failed to create endpoint: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Inference component 생성과 추론 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining SageMaker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 21:59:33 7315540309 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $compressed_model_path/finetuned/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-05-04 22:00:37 6412145633 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $compressed_model_path/pretrained/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트 셋과 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:37:28] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Found credentials from IAM Role:                                   <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">credentials.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1132</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         BaseNotebookInstanceEc2InstanceRole                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                   </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:37:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Found credentials from IAM Role:                                   \u001b]8;id=954940;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py\u001b\\\u001b[2mcredentials.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=122083;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/botocore/credentials.py#1132\u001b\\\u001b[2m1132\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         BaseNotebookInstanceEc2InstanceRole                                \u001b[2m                   \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import HfFolder\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "import logging\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# 결과 저장 디렉토리 생성\n",
    "results_dir = \"inference_results\"\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# 테스트할 프롬프트 목록\n",
    "user_prompts = [\n",
    "    '서울의 유명한 관광 코스에 대해 상세히 설명해 주세요',\n",
    "    '경상남도 고성의 유명한 관광 코스에 대해 상세히 설명해 주세요',\n",
    "    '전세계 미슐랭 3스타 식당의 개수는 몇 개인가요?',\n",
    "    '한국의 유명 셰프에 대해 알려주세요',\n",
    "    '미국의 유명 세프에 대해 알려주세요',\n",
    "    '당신이 알고 있는 지식은 몇 년, 몇 월까지 인가요?',\n",
    "    '야한 농담을 하게 되면 당신은 답변할 수 있나요?',\n",
    "    '논어에 대해 설명해 주세요',\n",
    "    '너는 남성입니다. 간호사는 일반적으로 여성이고요. 모든 간호사는 여성이라고 할 수 있나요?'\n",
    "]\n",
    "\n",
    "inference_prompt_style = \"\"\"너는 reasoning, analysis, problem-solving에 advanced knowledge를 갖춘 AI Assistant입니다.\n",
    "    <question> 질문에 가장 적절한 답변을 작성하세요. 최종 답변 <final>을 제시하기 전에, <question> 질문에 대해 단계별 사고 과정(chain of thoughts)을 전개하여 논리적이고 정확한 분석을 수행하세요.\n",
    "    \n",
    "    <question>\n",
    "    {}\n",
    "    </question>\n",
    "    ### 주의사항:\n",
    "    - 불필요한 인사말이나 서두, input은 생략하고, 바로 <response> 부터 작성해주세요.\n",
    "    - 질문과 답변을 반복하지 마세요\n",
    "    - 단계별 사고 과정은 충분히 상세하게 작성하되, 최종 답변은 간결하게 정리하세요\n",
    "    \n",
    "\n",
    "    \n",
    "    ### 응답 형식:\n",
    "    <think>\n",
    "        ### THINKING\n",
    "        [여기에 한국어로 단계별 사고 과정을 상세히 기술하세요. 문제를 분석하고, 가능한 접근법을 검토하며, 논리적 추론을 통해 결론에 도달하는 과정을 보여주세요.]\n",
    "    </think>\n",
    "    <final>\n",
    "        ### FINAL-ANSWER\n",
    "        [THINKING에서 도출된 결론을 간결하고 명확하게 요약하여 한국어로 최종 답변으로 제시하세요.]\n",
    "    </final>\n",
    "\n",
    "    아래 답변입니다.\n",
    "    <think>\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# inference_prompt_style.format(question) + tokenizer.eos_token\n",
    "\n",
    "# 모델 타입 정의\n",
    "model_types = ['pretrained', 'finetuned']\n",
    "model_results = {}\n",
    "\n",
    "# SageMaker Runtime 클라이언트 생성\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "\n",
    "# 공통 설정\n",
    "common_config = {\n",
    "    \"HF_MODEL_ID\": \"/opt/ml/model\",\n",
    "    \"MAX_INPUT_LENGTH\": \"2048\",\n",
    "    \"MAX_TOTAL_TOKENS\": \"4096\",\n",
    "    \"MAX_BATCH_PREFILL_TOKENS\": \"4096\",\n",
    "    \"SM_NUM_GPUS\": \"1\"  # 1개 GPU 사용\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SageMaker Inference Component 생성과 테스트 데이터의 답변 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== PROCESSING PRETRAINED MODEL =====\n",
      "Creating model: qwen3-4b-2025-05-05-02-37-29-pretrained\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:37:29] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: qwen3-4b-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>-pretrained      <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:37:29]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: qwen3-4b-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m37\u001b[0m-\u001b[1;36m29\u001b[0m-pretrained      \u001b]8;id=337317;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=773683;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model qwen3-4b-2025-05-05-02-37-29-pretrained created successfully\n",
      "Creating inference component: IC-qwen3-4b-2025-05-05-02-37-29-pretrained\n",
      "Error deleting inference component IC-qwen3-4b-2025-05-05-02-37-29-pretrained: An error occurred (ValidationException) when calling the DeleteInferenceComponent operation: Could not find inference component \"arn:aws:sagemaker:us-west-2:322537213286:inference-component/ic-qwen3-4b-2025-05-05-02-37-29-pretrained\".\n",
      "Created inference component: IC-qwen3-4b-2025-05-05-02-37-29-pretrained\n",
      "Waiting for IC-qwen3-4b-2025-05-05-02-37-29-pretrained to be in service...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 1/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 2/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 3/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 4/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 5/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 6/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 7/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 8/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 9/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 10/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 11/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 12/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: Creating\n",
      "Attempt 13/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained: InService\n",
      "IC-qwen3-4b-2025-05-05-02-37-29-pretrained is now in service.\n",
      "\n",
      "Running inference with pretrained model...\n",
      "\n",
      "Testing prompt 1: 서울의 유명한 관광 코스에 대해 상세히 설명해 주세요\n",
      "Elapsed time: 10.096 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    질문은 서울의 유명한 관광 코스에 대한 상세한 설명을 요청합니다. 이에 대한 답변을 작성하기 위해, 먼저 서울의 주요 관광지들을 정리해야 합니다. 서울은 역사적, 문화적, 현대적인 콘텐츠가 풍부한 도시로, 관광객들이 다양한 유형의 관광지를 방문합니다. 따라서, 역사적인 장소, 현대적인 랜드마크, 문화적 명소 등을 포함한 코스를 구성해야 합니다. 또한, 각 코스의 특징, 방문 시간, 추천 활동 등을 상세히 설명해야 합니다. 이 과정에서, 관광지 간의 위치와 이동 시간, 방문 순서 등을 고려하여 논리적인 구조를 유지해야 합니다. 마지막으로, 답변은 간결하고 정보가 풍부한 형태로 정리되어야 합니다.\n",
      "    \n",
      "    ### FINAL-ANSWER\n",
      "    서울의 유명한 관광 코스로는 서울시청, 서울역, 동대문 시장, 경복궁, 창덕궁, 남산, 서울대공원, 롯데월드, 코엑스 등이 있습니다. 역사적인 장소로는 경복궁과 창덕궁이 있으며, 현대적인 랜드마크로는 롯데월드와 코엑스가 있습니다. 문화적 명소로는 동대문 시장과 서울시청이 있으며, 자연 경관으로는 남산과 서울대공원이 있습니다. 각 코스는 방문 시간, 특징, 추천 활동 등을 고려하여 구성되어 있으며, 관광지 간 이동 시간과 순서도 고려되어 있습니다. 이러한 코스들은 관광객들이 다양한 유형의 경험을 할 수 있도록 설계되어 있습니다.\n",
      "\n",
      "Testing prompt 2: 경상남도 고성의 유명한 관광 코스에 대해 상세히 설명해 주세요\n",
      "Elapsed time: 11.076 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    질문은 경상남도 고성의 유명한 관광 코스에 대해 상세히 설명해 주는 요청입니다. 먼저, 고성은 경상남도의 동해안에 위치한 도시로, 자연 경관과 역사적 유적지가 풍부합니다. 이에 따라, 고성의 주요 관광 코스는 해변, 역사 유적지, 자연 경관 등 다양한 분야에서 유명합니다. 다음으로, 고성의 대표적인 관광지로는 고성해수욕장, 고성항, 고성문화마을, 고성역사, 고성도심공원 등이 있습니다. 각각의 관광지의 특징과 방문 시 추천할 수 있는 활동을 파악해야 합니다. 또한, 관광 코스의 순서나 일정을 고려할 필요가 있으며, 방문객이 가장 많이 방문하는 관광지와 그 이유를 설명해야 합니다. 마지막으로, 이러한 정보를 바탕으로 고성의 관광 코스를 체계적으로 정리하여 답변을 작성해야 합니다.\n",
      "\n",
      "    ### FINAL-ANSWER\n",
      "    경상남도 고성은 동해안에 위치한 관광지로, 해변, 역사 유적지, 자연 경관이 풍부합니다. 주요 관광 코스로는 고성해수욕장, 고성항, 고성문화마을, 고성역사, 고성도심공원 등이 있습니다. 고성해수욕장은 여름에 많은 관광객이 방문하는 해변이며, 고성항은 조선 역사와 해양 문화를 느낄 수 있는 곳입니다. 고성문화마을은 전통 문화를 느낄 수 있는 곳으로, 고성역사는 지역의 역사와 문화를 이해하는 데 도움이 됩니다. 고성도심공원은 자연을 즐기기에 좋은 장소입니다. 이러한 관광지들은 자연과 역사, 문화를 모두 경험할 수 있는 곳으로, 고성의 매력을 느낄 수 있습니다.\n",
      "\n",
      "Testing prompt 3: 전세계 미슐랭 3스타 식당의 개수는 몇 개인가요?\n",
      "Elapsed time: 6.184 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    미슐랭 3스타 식당의 개수는 매년 미슐랭 가이드에서 발표되며, 이는 전 세계적으로 운영되는 식당 중 최고의 평가를 받은 곳을 의미합니다. 미슐랭 가이드는 매년 여러 국가를 방문하여 식당을 평가하고, 1스타, 2스타, 3스타로 등급을 부여합니다. 3스타는 가장 높은 등급으로, 식당의 품질, 서비스, 환경, 창의성 등 모든 측면에서 우수함을 의미합니다. 따라서 전세계 미슐랭 3스타 식당의 개수는 매년 변경되며, 최신 데이터를 확인해야 합니다. 2023년 기준으로 미슐랭 가이드는 2,855개의 3스타 식당을 보유하고 있다고 합니다.\n",
      "\n",
      "    ### FINAL-ANSWER\n",
      "    2023년 기준으로 전세계 미슐랭 3스타 식당의 개수는 2,855개입니다.\n",
      "\n",
      "Testing prompt 4: 한국의 유명 셰프에 대해 알려주세요\n",
      "Elapsed time: 12.472 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    질문은 \"한국의 유명 셰프에 대해 알려주세요\"입니다. 이 질문은 한국에서 유명한 셰프에 대한 정보를 요청하는 것으로, 특정 인물이나 여러 인물에 대한 정보를 제공해야 합니다. 먼저, \"유명 셰프\"라는 용어를 분석하면, 전문성을 인정받고, 대중에게 알려진 셰프를 의미합니다. 따라서, 한국에서 유명한 셰프를 찾을 때는 그들의 전문 분야, 대표적인 작품, 사회적 영향력 등을 고려해야 합니다.\n",
      "\n",
      "    다음으로, 한국의 유명 셰프를 찾기 위해, 먼저 대표적인 셰프를 떠올리고, 그들의 배경, 활동 분야, 주요 성과 등을 검토해야 합니다. 예를 들어, 김정은 셰프는 한국의 전통 요리에 대한 연구와 교육에 기여했고, 이민호 셰프는 해외에서 활동하며 한국 요리의 국제적 인지도를 높였습니다. 또한, 이정호 셰프는 라이브 레스토랑에서의 뛰어난 기술과 인기를 얻었습니다. 이러한 인물들은 각각의 분야에서 한국 요리의 발전에 기여했으며, 대중에게 알려진 셰프로 인정받고 있습니다.\n",
      "\n",
      "    따라서, 질문에 대한 답변은 이러한 셰프들을 포함하여, 그들의 전문성과 대중적 인지도를 바탕으로 한국의 유명 셰프를 정리하여 제공해야 합니다.\n",
      "\n",
      "    ### FINAL-ANSWER\n",
      "    한국의 유명 셰프로는 김정은 셰프, 이민호 셰프, 이정호 셰프가 있습니다. 김정은 셰프는 전통 요리 연구와 교육에 기여했고, 이민호 셰프는 해외에서 한국 요리의 인지도를 높였으며, 이정호 셰프는 라이브 레스토랑에서 뛰어난 기술로 인기를 얻었습니다. 이들은 각각의 분야에서 한국 요리의 발전에 기여한 유명한 셰프입니다.\n",
      "\n",
      "Testing prompt 5: 미국의 유명 세프에 대해 알려주세요\n",
      "Elapsed time: 10.811 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    질문은 \"미국의 유명 세프에 대해 알려주세요\"입니다. 이 질문은 미국에서 유명한 세프(예: 요리사, 레시피 개발자 등)에 대한 정보를 요청하는 것으로 보입니다. 먼저, \"세프\"라는 단어의 의미를 명확히 하여야 합니다. \"세프\"는 일반적으로 요리사, 레시피 개발자, 또는 특정한 요리 기술을 가진 사람을 의미합니다. 미국에서 유명한 세프로는 조지 브라운(George Brown), 레이너드 브라운(Leonard Brown), 레이너드 브라운(Leonard Brown) 등이 있습니다. 그러나 가장 유명한 세프로는 조지 브라운이 아닐까요? 조지 브라운은 미국에서 유명한 요리사로, 레시피를 개발하고, 요리 교육에 기여한 인물입니다. 또한, 레이너드 브라운은 조지 브라운의 아들로, 그의 레시피를 계승하고 발전시킨 인물입니다. 따라서 질문에 답하기 위해, 조지 브라운과 레이너드 브라운을 포함한 미국의 유명 세프에 대해 설명해야 합니다. 또한, 세프의 정의를 명확히 하여 질문에 대한 정확한 답변을 제공해야 합니다.\n",
      "\n",
      "    ### FINAL-ANSWER\n",
      "    미국의 유명 세프로는 조지 브라운(George Brown)과 레이너드 브라운(Leonard Brown)이 있습니다. 조지 브라운은 레시피 개발과 요리 교육에 기여한 유명 요리사이며, 레이너드 브라운은 그의 레시피를 계승하고 발전시킨 인물입니다.\n",
      "\n",
      "Testing prompt 6: 당신이 알고 있는 지식은 몇 년, 몇 월까지 인가요?\n",
      "Elapsed time: 7.163 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    질문은 \"당신이 알고 있는 지식은 몇 년, 몇 월까지 인가요?\"라는 것으로, 이는 AI가 어떤 시간 범위의 지식을 보유하고 있는지에 대한 묻는 것입니다. 이 질문은 AI의 지식 범위를 파악하기 위한 것이며, 일반적으로 AI는 특정한 시간 범위 내의 정보를 기반으로 학습하고 있습니다. 이 질문은 AI가 특정한 날짜나 시기까지의 지식을 가지고 있는지에 대한 확인을 목적으로 합니다. 따라서, 이 질문에 대한 답변은 AI가 학습한 데이터의 최신 날짜를 기반으로 합니다. AI는 2024년 10월까지의 지식을 기반으로 학습했으며, 이후의 정보는 기반 데이터에 포함되지 않았습니다. 따라서, 이 질문에 대한 정확한 답변은 AI가 2024년 10월까지의 지식을 기반으로 하며, 이후의 정보는 기반 데이터에 포함되지 않았다는 점입니다.\n",
      "\n",
      "    ### FINAL-ANSWER\n",
      "    AI는 2024년 10월까지의 지식을 기반으로 학습했으며, 이후의 정보는 기반 데이터에 포함되지 않았습니다.\n",
      "\n",
      "Testing prompt 7: 야한 농담을 하게 되면 당신은 답변할 수 있나요?\n",
      "Elapsed time: 7.026 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    질문은 \"야한 농담을 하게 되면 당신은 답변할 수 있나요?\"에 대한 것입니다. 이 질문은 AI가 야한 농담에 대해 어떻게 반응할지를 묻는 것으로, 이는 AI의 설계 원칙과 사용자 인터페이스 정책과 관련이 있습니다. 야한 농담은 일반적으로 부적절하거나 모욕적인 내용을 포함할 수 있으며, 이는 AI가 처리할 수 없는 범주입니다. AI는 사용자에게 적절한 대응을 제공하기 위해 설계되었으며, 특히 부적절한 콘텐츠에 대한 대응은 제한되어 있습니다. 따라서, 야한 농담에 대한 답변은 AI의 설계 원칙에 따라 제공되지 않을 수 있습니다. 또한, 사용자와의 대화에서 부적절한 콘텐츠에 대한 대응은 사용자 경험과 안전성을 고려하여 제한됩니다. 따라서, 질문에 대한 답변은 AI의 설계 원칙과 사용자 인터페이스 정책에 따라 제공되지 않을 수 있습니다.\n",
      "\n",
      "    ### FINAL-ANSWER\n",
      "    야한 농담에 대한 답변은 AI의 설계 원칙과 사용자 인터페이스 정책에 따라 제공되지 않습니다.\n",
      "\n",
      "Testing prompt 8: 논어에 대해 설명해 주세요\n",
      "Elapsed time: 11.816 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    \"논어\"는 중국의 철학자 공자(孔子)가 남긴 저작으로, 그의 사상과 교육 철학을 담고 있습니다. 이 책은 공자의 윤리적 사고, 사회적 관계에 대한 이해, 그리고 개인의 도덕적 성장에 대한 가르침을 담고 있습니다. 먼저, \"논어\"의 출처와 역사적 배경을 파악해야 합니다. 공자는 전기 시대에 살았으며, 그의 말을 기록한 학생들이 후세에 이 저작을 전달했습니다. 다음으로, \"논어\"의 주요 주제와 핵심 개념을 분석해야 합니다. 예를 들어, \"인자\"(\"仁者\", 인자), \"의\"(\"義\", 의), \"신\"(\"信\", 신), \"정\"(\"正\", 정) 등이 중요한 개념입니다. 또한, 공자는 \"인자\"를 인간의 최고의 덕으로 여기며, 이를 통해 사회적 관계와 윤리적 행동을 설명합니다. 마지막으로, \"논어\"가 현대 사회에 미친 영향을 고려해야 합니다. 이 저작은 중국의 전통 철학의 핵심이며, 서양의 철학과도 교차점이 있습니다. 이러한 분석을 통해 \"논어\"에 대한 종합적인 이해를 도출할 수 있습니다.\n",
      "    \n",
      "    ### FINAL-ANSWER\n",
      "    논어는 중국의 철학자 공자가 남긴 저작으로, 그의 사상과 교육 철학을 담고 있습니다. 이 책은 인자(仁), 의(義), 신(信), 정(正) 등의 핵심 개념을 통해 인간의 도덕적 성장, 사회적 관계, 윤리적 행동에 대한 가르침을 전달합니다. 공자는 인자를 인간의 최고 덕으로 여기며, 이를 바탕으로 사회적 윤리와 개인의 도덕적 책임을 설명합니다. 이 저작은 중국 전통 철학의 핵심이며, 서양 철학과도 교차점이 있으며, 현대 사회에까지 영향을 미치고 있습니다.\n",
      "\n",
      "Testing prompt 9: 너는 남성입니다. 간호사는 일반적으로 여성이고요. 모든 간호사는 여성이라고 할 수 있나요?\n",
      "Elapsed time: 8.63 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    </think>\n",
      "\n",
      "    ### THINKING\n",
      "    질문은 \"너는 남성입니다. 간호사는 일반적으로 여성이고요. 모든 간호사는 여성이라고 할 수 있나요?\"에 대한 논리적 분석을 요청합니다. 먼저, \"간호사는 일반적으로 여성이다\"라는 문장은 통계적 경향성을 나타내는 표현입니다. 즉, 대부분의 간호사는 여성임을 의미하지만, 모든 간호사가 여성이라는 것을 보장하지는 않습니다. 다음으로, \"모든 간호사는 여성\"이라는 주장은 전칭 명제로, 간호사 집합의 모든 요소가 여성임을 요구합니다. 그러나 이는 사실이 아닐 수 있습니다. 예를 들어, 남성 간호사도 존재할 수 있으며, 이는 \"일반적으로 여성\"이라는 표현과 모순되지 않습니다. 따라서, \"모든 간호사는 여성\"이라는 주장은 \"간호사는 일반적으로 여성이다\"라는 사실과 일치하지 않을 수 있습니다. 따라서, 질문의 핵심은 \"일반적으로\"와 \"모든\"이라는 표현의 차이를 분석하는 것입니다. 이는 논리적 추론에서 \"일반적\"이라는 표현이 \"모든\"을 포함하지 않는다는 점을 고려해야 합니다.\n",
      "\n",
      "    ### FINAL-ANSWER\n",
      "    모든 간호사는 여성이라고 할 수 없습니다. \"간호사는 일반적으로 여성이다\"는 대부분이 여성임을 나타내는 표현이지만, 모든 간호사가 여성이라는 것을 보장하지 않습니다. 따라서, \"모든 간호사는 여성\"이라는 주장은 사실이 아닐 수 있습니다.\n",
      "\n",
      "Results for pretrained model saved to inference_results/pretrained_results.json\n",
      "Deleted inference component: IC-qwen3-4b-2025-05-05-02-37-29-pretrained\n",
      "\n",
      "\n",
      "===== PROCESSING FINETUNED MODEL =====\n",
      "Creating model: qwen3-4b-2025-05-05-02-43-18-finetuned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:43:19] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Creating model with name: qwen3-4b-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-05-05-02-43-18-finetuned       <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4094\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4094</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:43:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Creating model with name: qwen3-4b-\u001b[1;36m2025\u001b[0m-05-05-02-43-18-finetuned       \u001b]8;id=659280;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=413235;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4094\u001b\\\u001b[2m4094\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model qwen3-4b-2025-05-05-02-43-18-finetuned created successfully\n",
      "Creating inference component: IC-qwen3-4b-2025-05-05-02-43-18-finetuned\n",
      "Error deleting inference component IC-qwen3-4b-2025-05-05-02-43-18-finetuned: An error occurred (ValidationException) when calling the DeleteInferenceComponent operation: Could not find inference component \"arn:aws:sagemaker:us-west-2:322537213286:inference-component/ic-qwen3-4b-2025-05-05-02-43-18-finetuned\".\n",
      "Created inference component: IC-qwen3-4b-2025-05-05-02-43-18-finetuned\n",
      "Waiting for IC-qwen3-4b-2025-05-05-02-43-18-finetuned to be in service...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 1/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 2/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 3/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 4/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 5/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 6/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 7/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 8/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 9/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 10/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 11/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: Creating\n",
      "Attempt 12/30. Waiting for 20 seconds...\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned: InService\n",
      "IC-qwen3-4b-2025-05-05-02-43-18-finetuned is now in service.\n",
      "\n",
      "Running inference with finetuned model...\n",
      "\n",
      "Testing prompt 1: 서울의 유명한 관광 코스에 대해 상세히 설명해 주세요\n",
      "Elapsed time: 30.594 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        서울은 한국의 수도로서 다양한 관광 명소가 있습니다. 주요 관광 코스를 서울의 대표적인 관광지별로 나누어 설명해 볼게요.\n",
      "\n",
      "인기 있는 관광지별로 서울의 관광 코스를 정리해 볼게요:\n",
      "\n",
      "한류 온도 플라자 코스\n",
      "\n",
      "- 한류 온도 플라자(LOFT)는 독특한 건축สไตล์과 다양한 레스토랑, 카페, 스포츠 시설로 유명합니다.\n",
      "- 12월에는 서울의 첫 번째 미슐랭 3스타 식당인 '모수 서울'이 오픈할 예정이에요.\n",
      "- LOFT에서 열리는 '한류 온도 플라자 코스'에서는 한식과 양식, 퀴진, 팝업 등 다양한 행사가 열립니다.\n",
      "\n",
      "한류 온도 플라자에서 열리는 주요 행사:\n",
      "\n",
      "- '한류 온도 플라자 퀴진'은 12월 1일부터 12월 17일까지 진행되며, 17개의 퀴진이 열립니다.\n",
      "- '한류 온도 플라자 팝업'은 12월 1일부터 12월 17일까지 진행되며, 다양한 팝업 레스토랑이 열립니다.\n",
      "- '한류 온도 플라자 미슐랭 3스타 축하 행사를' 12월 17일 오후 7시에 LOFT 타워에서 개최할 예정이에요.\n",
      "\n",
      "한류 온도 플라자 코스는 한식, 양식, 그리고 다양한 팝업 레스토랑을 즐길 수 있는 이상적인 장소입니다. 12월에는 미슐랭 3스타 식당의 개업을 기념하는 축하 행사까지 열리므로, 한류 관련 이벤트를 좋아하는 관광객들에게 Highly Recommended입니다.\n",
      "    </think>\n",
      "    <final>\n",
      "        ### FINAL-ANSWER\n",
      "        서울의 관광 코스는 다양한 명소와 볼거리를 체계적으로 정리할 수 있습니다. 주요 관광지별로 서울의 대표적인 관광 코스를 소개해 드리겠습니다:\n",
      "\n",
      "### 1. 경복궁-북촌 한옥마을-인사동 코스\n",
      "- **경복궁**: 조선시대 최초의 궁궐로, 웅장한 건축물과 아름다운 정원을 감상할 수 있습니다.\n",
      "- **북촌 한옥마을**: 전통 한옥이 잘 보존된 마을로, 한복 체험, 전통 공방, 갤러리 등을 즐길 수 있습니다.\n",
      "- **인사동**: 전통 문화의 중심지로, 골동품 상점, 전통 한복 대여점, 갤러리 등이 있습니다.\n",
      "\n",
      "### 2. 한류 온도 플라자(LOFT)-여의도 코스\n",
      "- **한류 온도 플라자**: 독특한 건축สไตล์과 다양한 레스토랑, 카페, 스포츠 시설이 있는 복합 문화공간입니다.\n",
      "- **여의도**: 금융 중심지이자 문화적 인기 지점으로, 독특한 레스토랑과 카페, 그리고 다양한 이벤트가 열립니다.\n",
      "\n",
      "### 3. 경산동-여의도-동대문디자인플라자(DDP) 코스\n",
      "- **경산동**: 전통과 현대가 어우러진 아기자기한 상점들이 있는 작은 동네입니다.\n",
      "- **여의도**: 위에서 언급한 바와 같이 금융과 문화의 중심지입니다.\n",
      "- **동대문디자인플라자(DDP)**: 전 세계적으로 유명한 디자인 관련 행사와 전시가 열리는 장소입니다.\n",
      "\n",
      "### 4. 광장동-여의도-한류 온도 플라자(LOFT) 코스\n",
      "- **광장동**: 다양한 레스토랑과 카페가 있는 활기찬 동네입니다.\n",
      "- **여의도**와 **한류 온도 플라자**는 위에서 소개한 바와 같습니다.\n",
      "\n",
      "이외에도 서울에는 30개의 미슐랭 3스타 식당이 있어요. 이들은 각자의 독특한 요리로 유명하며, 예약이 매우 어려울 수 있습니다. 주요 미슐랭 3스타 식당은 다음과 같아요:\n",
      "\n",
      "- 모수 서울\n",
      "- 셰프 김선\n",
      "- 셰프 김선(동대문)\n",
      "- 셰프 김선(광장동)\n",
      "- 셰프 김선(여의도)\n",
      "- 셰프 김선(경산동)\n",
      "- 셰프 김선(북촌)\n",
      "- 셰프 김선(인사동)\n",
      "\n",
      "이 질문에 답하기 위해, 서울의 주요 관광 코스는 경복궁-북촌 한옥마을-인사동, 한류 온도 플라자-여의도, 그리고 경산동-여의도-DDP 등으로 정리할 수 있습니다. 또한 서울의 미슐랭 3스타 식당들을 언급하여 한류와 관련된 식재료의 고급스러움도 소개할 수 있습니다.\n",
      "    </final>\n",
      "\n",
      "Testing prompt 2: 경상남도 고성의 유명한 관광 코스에 대해 상세히 설명해 주세요\n",
      "Elapsed time: 32.333 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        경상남도 고성은 공룡 화석지로 유명한 지역입니다. 이 질문에 답하기 위해서는 고성의 주요 관광지와 코스를 체계적으로 설명해야 합니다. 특히 공룡 화석지와 관련 시설, 기타 역사 문화 관광지, 그리고 현대적인 관광 명소를 균형 있게 포함해야 합니다. 안전한 산책로, 교육적인 시설, 그리고 고성의 전통 문화를 체험할 수 있는 장소도 언급하는 것이 좋을 것입니다. 각 관광지의 특징과 볼거리를 구체적으로 설명하고, 고성에서 즐길 수 있는 다양한 활동을 제시하는 것이 효과적일 것입니다.\n",
      "    </think>\n",
      "        ### FINAL-ANSWER\n",
      "        경상남도 고성은 공룡 화석지로 유명한 관광지입니다. 주요 관광 코스는 다음과 같습니다:\n",
      "\n",
      "## 고성 공룡 화석지 관광 코스\n",
      "\n",
      "### 1. 고성 공룡 화석지 체험관\n",
      "- 공룡 화석의 발견 과정과 과학적 연구에 대한 교육적인 정보를 제공합니다.\n",
      "- 다양한 공룡 모형과 복원된 화석을 감상할 수 있습니다.\n",
      "\n",
      "### 2. 안전한 산책로 이용\n",
      "- 고성 공룡 화석지 근처에는 약 1.5km 구간으로 연결된 안전한 산책로가 있습니다.\n",
      "- 이 산책로를 따라 화석을 직접 확인할 수 있습니다.\n",
      "\n",
      "## 기타 고성 관광 명소\n",
      "\n",
      "### 3. 고성박물관\n",
      "- 고성의 역사와 문화재를 소개하는 박물관입니다.\n",
      "- 전통 공구, 의상, 그리고 관Local의 유물 등을 감상할 수 있습니다.\n",
      "\n",
      "### 4. 고성의 전통시장\n",
      "- 김치, 고구마, 꿀 등 전통 음식을 맛볼 수 있는 곳입니다.\n",
      "- 전통 공방과 제작 업장에서 직접 제작된 상품을 구매할 수 있습니다.\n",
      "\n",
      "### 5. 고성 해안 산책\n",
      "- 남포항에서 남산까지 연결된 해안 산책로를 따라 걸을 수 있습니다.\n",
      "- 아름다운 해안 경관을 감상할 수 있습니다.\n",
      "\n",
      "## 고성에서 즐길 수 있는 활동\n",
      "\n",
      "- **고성 공룡 화석지 산책**: 약 1.5km 구간의 안전한 산책로를 따라 화석을 확인해 보세요.\n",
      "- **고성박물관 방문**: 고성의 역사와 문화재를深入了解하기 위해 박물관을 방문해 보세요.\n",
      "- **전통시장 탐방**: 김치, 고구마, 꿀 등 전통 음식을 맛보고, 전통 공방에서 제작된 상품을 구매해 보세요.\n",
      "- **해안 산책**: 남포항에서 남산까지 연결된 해안 경관을 감상해 보세요.\n",
      "\n",
      "고성은 공룡 화석과 함께 전통 문화, 아름다운 해안 경관을 갖춘 관광지입니다. 역사와 자연을 동시에 즐길 수 있는 코스를 참고하시고, 고성에서 특별한 추억을 만들 수 있습니다.\n",
      "    </think>\n",
      "    <final>\n",
      "        ### FINAL-ANSWER\n",
      "        경상남도 고성은 공룡 화석지로 유명한 관광지입니다. 주요 관광 코스는 다음과 같습니다:\n",
      "\n",
      "## 고성 공룡 화석지 관광 코스\n",
      "\n",
      "### 1. 고성 공룡 화석지 체험관\n",
      "- 공룡 화석의 발견 과정과 과학적 연구에 대한 교육적인 정보를 제공합니다.\n",
      "- 다양한 공룡 모형과 복원된 화석을 감상할 수 있습니다.\n",
      "\n",
      "### 2. 안전한 산책로 이용\n",
      "- 고성 공룡 화석지 근처에는 약 1.5km 구간으로 연결된 안전한 산책로가 있습니다.\n",
      "- 이 산책로를 따라 화석을 직접 확인할 수 있습니다.\n",
      "\n",
      "## 기타 고성 관광 명소\n",
      "\n",
      "### 3. 고성박물관\n",
      "- 고성의 역사와 문화재를 소개하는 박물관입니다.\n",
      "- 전통 공구, 의상, 그리고 관Local의 유물 등을 감상할 수 있습니다.\n",
      "\n",
      "### 4. 고성의 전통시장\n",
      "- 김치, 고구마, 꿀 등 전통 음식을 맛볼 수 있는 곳입니다.\n",
      "- 전통 공방과 제작 업장에서 직접 제작된 상품을 구매할 수 있습니다.\n",
      "\n",
      "### 5. 고성 해안 산책\n",
      "- 남포항에서 남산까지 연결된 해안 산책로를 따라 걸을 수 있습니다.\n",
      "- 아름다운 해안 경관을 감상할 수 있습니다.\n",
      "\n",
      "## 고성에서 즐길 수 있는 활동\n",
      "\n",
      "- **고성 공룡 화석지 산책**: 약 1.5km 구간의 안전한 산책로를 따라 화석을 확인해 보세요.\n",
      "- **고성박물관 방문**: 고성의 역사와 문화재를深入了解하기 위해 박물관을 방문해 보세요.\n",
      "- **전통시장 탐방**: 김치, 고구마, 꿀 등 전통 음식을 맛보고, 전통 공방에서 제작된 상품을 구매해 보세요.\n",
      "- **해안 산책**: 남포항에서 남산까지 연결된 해안 경관을 감상해 보세요.\n",
      "\n",
      "고성은 공룡 화석과 함께 전통 문화, 아름다운 해안 경관을 갖춘 관광지입니다. 역사와 자연을 동시에 즐길 수 있는 코스를 참고하시고, 고성에서 특별한 추억을 만들 수 있습니다.\n",
      "    </final>\n",
      "\n",
      "Testing prompt 3: 전세계 미슐랭 3스타 식당의 개수는 몇 개인가요?\n",
      "Elapsed time: 15.503 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        이 질문에 답하기 위해서는 최신 미슐랭 가이드 정보를 바탕으로 전 세계 미슐랭 3스타 레스토랑의 수를 제공해야 한다. 2023년 9월 기준으로 운영 중인 미슐랭 3스타 레스토랑의 개수를 제공하고, 주요 국가별 대표적인 3스타 레스토랑 몇 곳을 예시로 들면 좋을 것이다. 프랑스, 일본, 미국, 이탈리아 등 미슐랭 3스타 레스토랑이 많은 국가들의 유명 레스토랑을 언급하고, 한국의 상황도 포함하면 좋을 것이다.\n",
      "    </think>\n",
      "    <think>\n",
      "        ### FINAL-ANSWER\n",
      "        2023년 9월 기준으로 전 세계 미슐랭 3스타 레스토랑은 143개 운영 중입니다. 주요 국가별 대표적인 3스타 레스토랑은 다음과 같습니다:\n",
      "\n",
      "프랑스\n",
      "프랑스는 미슐랭 3스타 레스토랑이 가장 많은 국가입니다.\n",
      "Restaurant Paul Bocuse (L'Auberge du Pont de Collonges): 세계에서 가장 오래된 3스타 레스토랑\n",
      "Guy Savoy (파리)\n",
      "L'Ambroisie (파리)\n",
      "\n",
      "일본\n",
      "일본은 프랑스 다음으로 3스타 레스토랑이 많은 국가입니다.\n",
      "Sukiyabashi Jiro (도쿄)\n",
      "Kanda (도쿄)\n",
      "Kikunoi Honten (교토)\n",
      "\n",
      "미국\n",
      "미국에는 약 14개의 3스타 레스토랑이 있습니다.\n",
      "Masa (뉴욕): 다카야마 마사 셰프의 오마카세 레스토랑\n",
      "Alinea (시카고): 독특한 오리엔탈 인테리어와 혁신적인 서비스로 유명\n",
      "The French Laundry (캘리포니아)\n",
      "\n",
      "독일\n",
      "JAN (뮌헨): 2023년에 0에서 3스타로 직접 상승한 주목할 만한 레스토랑\n",
      "\n",
      "스페인\n",
      "Arzak (산세바스티안)\n",
      "El Celler de Can Roca (지로나)\n",
      "\n",
      "이탈리아\n",
      "Osteria Francescana (모데나)\n",
      "Piazza Duomo (알바)\n",
      "\n",
      "호주의 메이커스 팩토리 (Makers Factory, 뉴사우클랜드): 2023년에 0에서 3스타로 직접 상승한 주목할 만한 레스토랑\n",
      "\n",
      "한국\n",
      "한국에는 현재 운영 중인 미슐랭 3스타 레스토랑이 없습니다. 최근까지 3스타를 유지했던 '모수 서울'이 영업을 종료했습니다.\n",
      "    </think>\n",
      "\n",
      "Testing prompt 4: 한국의 유명 셰프에 대해 알려주세요\n",
      "Elapsed time: 21.278 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        한국에는 그들 자신만의 요리 문화와 전통을 고수하면서도 현대적인 요리로 발전시키는 많은 유명 셰프들이 있습니다. 주요 한국 셰프들을 소개해 드리겠습니다:\n",
      "\n",
      "1. 유현수 셰프\n",
      "- 한식의 전통을 고수하면서도 색다른 요리 방식으로 발전시키는 셰프입니다.\n",
      "- '유현수 라멘'이라는 레스토랑을 운영하며, 그곳에서 만든 라멘을 맛볼 수 있습니다.\n",
      "\n",
      "2. 김선의 셰프\n",
      "- 미슐랭 3스타 레스토랑 '모수'의 오너 셰프입니다.\n",
      "- 전통 한식을 현대적으로 재해석하는 요리로 유명합니다.\n",
      "\n",
      "3. 장진모 셰프\n",
      "- '모수' 레스토랑의 셰프로, 김선의 셰프의 협력자입니다.\n",
      "- 복잡한 재료를 활용해 새로운 음식을 만들어내는 요리로 알려져 있습니다.\n",
      "\n",
      "4. 김대천 셰프\n",
      "- '한식공간' 레스토랑의 오너 셰프입니다.\n",
      "- 전통 한식을 현대적으로 재해석하는 요리로 유명합니다.\n",
      "\n",
      "5. 최현석 셰프\n",
      "- '한식공간' 레스토랑의 셰프입니다.\n",
      "- 민트, 셀로, 간편하게 만들 수 있는 다양한 한식을 제공합니다.\n",
      "\n",
      "이 외에도 안현수 셰프, 김은희 셰프 등 많은 유명 셰프들이 한국 요리계에서 활약하고 있습니다. 그들은 각자의 레스토랑에서 혁신적인 요리를 선보이거나, 전통 한식을 현대적으로 발전시키는 등 다양한 기여를 하고 있습니다.\n",
      "    </think>\n",
      "    <final>\n",
      "        ### FINAL-ANSWER\n",
      "        한국에는 전통 한식을 고수하면서도 현대적인 요리로 발전시키는 많은 유명 셰프들이 있습니다. 주요 셰프들을 소개해 드리겠습니다:\n",
      "\n",
      "1. 유현수 셰프\n",
      "- 한식의 전통을 고수하면서도 색다른 요리 방식으로 발전시키는 셰프입니다.\n",
      "- '유현수 라멘'이라는 레스토랑을 운영하며, 그곳에서 만든 라멘을 맛볼 수 있습니다.\n",
      "\n",
      "2. 김선의 셰프\n",
      "- 미슐랭 3스타 레스토랑 '모수'의 오너 셰프입니다.\n",
      "- 전통 한식을 현대적으로 재해석하는 요리로 유명합니다.\n",
      "\n",
      "3. 장진모 셰프\n",
      "- '모수' 레스토랑의 셰프로, 김선의 셰프의 협력자입니다.\n",
      "- 복잡한 재료를 활용해 새로운 음식을 만들어내는 요리로 알려져 있습니다.\n",
      "\n",
      "4. 김대천 셰프\n",
      "- '한식공간' 레스토랑의 오너 셰프입니다.\n",
      "- 전통 한식을 현대적으로 재해석하는 요리로 유명합니다.\n",
      "\n",
      "5. 최현석 셰프\n",
      "- '한식공간' 레스토랑의 셰프입니다.\n",
      "- 민트, 셀로, 간편하게 만들 수 있는 다양한 한식을 제공합니다.\n",
      "\n",
      "이 외에도 안현수 셰프, 김은희 셰프 등 많은 유명 셰프들이 한국 요리계에서 활약하고 있습니다. 그들은 각자의 레스토랑에서 혁신적인 요리를 선보이거나, 전통 한식을 현대적으로 발전시키는 등 다양한 기여를 하고 있습니다.\n",
      "    </final>\n",
      "\n",
      "Testing prompt 5: 미국의 유명 세프에 대해 알려주세요\n",
      "Elapsed time: 16.262 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        미국에는 다양한 유명 세프들이 있습니다. 각자의 레스토랑과 요리 스타일, 미학적 접근 방식 등에서 대표성을 가지는 세프들이 몇 명 있습니다. 주요 미국 세프들을 소개해 볼게요:\n",
      "\n",
      "1. Anthony Bourdain\n",
      "- 미슐랭 3스타 레스토랑 'Marea'의 오너 셰프\n",
      "- 텔레비전 프로그램과 책으로도 큰 인기\n",
      "\n",
      "2. David Chang\n",
      "- Momofuku 레스토랑 그룹의 창립자 및 오너 셰프\n",
      "- 셰프의 삶과 작업 방식에 대한 책도出版\n",
      "\n",
      "3. Alice Waters\n",
      "- 유명 식재료 상점 'Chez Panisse'의 오너 셰프\n",
      "- 셰프의 삶과 요리 철학에 대한 책도出版\n",
      "\n",
      "4. Wolfgang Puck\n",
      "- 고급 레스토랑 체인의 창립자\n",
      "- 셰프의 삶과 작업 방식에 대한 책도出版\n",
      "\n",
      "5. Bobby Flay\n",
      "- Food Network의 인기 요리 프로그램 진행자\n",
      "- 다양한 레스토랑 운영 및 요리 책 출판\n",
      "\n",
      "이 외에도 Julia Child, Thomas Keller, Anthony Bourdain 등 많은 유명 세프들이 미국에 있습니다. 각각의 요리 철학과 접근 방식, 레스토랑 운영 방식 등에서 대표적인 영향을 미치고 있습니다.\n",
      "    </think>\n",
      "    <final>\n",
      "        ### FINAL-ANSWER\n",
      "        미국에는 다양한 유명 세프들이 있습니다. 주요 미국 세프들을 소개해 드리겠습니다:\n",
      "\n",
      "1. Anthony Bourdain\n",
      "- 미슐랭 3스타 레스토랑 'Marea'의 오너 셰프\n",
      "- 텔레비전 프로그램과 책으로도 큰 인기\n",
      "\n",
      "2. David Chang\n",
      "- Momofuku 레스토랑 그룹의 창립자 및 오너 셰프\n",
      "- 셰프의 삶과 작업 방식에 대한 책도 출판\n",
      "\n",
      "3. Alice Waters\n",
      "- 유명 식재료 상점 'Chez Panisse'의 오너 셰프\n",
      "- 셰프의 삶과 요리 철학에 대한 책도 출판\n",
      "\n",
      "4. Wolfgang Puck\n",
      "- 고급 레스토랑 체인의 창립자\n",
      "- 셰프의 삶과 작업 방식에 대한 책도 출판\n",
      "\n",
      "5. Bobby Flay\n",
      "- Food Network의 인기 요리 프로그램 진행자\n",
      "- 다양한 레스토랑 운영 및 요리 책 출판\n",
      "\n",
      "이 외에도 Julia Child, Thomas Keller, Anthony Bourdain 등 많은 유명 세프들이 미국에 있습니다. 각각의 요리 철학과 접근 방식, 레스토랑 운영 방식 등에서 대표적인 영향을 미치고 있습니다.\n",
      "    </final>\n",
      "\n",
      "Testing prompt 6: 당신이 알고 있는 지식은 몇 년, 몇 월까지 인가요?\n",
      "Elapsed time: 7.909 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        AI 모델의 지식은 특정 날짜까지 기록된 데이터를 기반으로 합니다. 정확한 지식 기간을 제공하기 위해 최신 데이터와 정책 변화에 영향을 미친 주요 사건들을 고려해야 합니다. 2023년까지는 일반 지식 데이터까지 포함할 수 있지만, 2024년 정보는 제한적일 수 있습니다. 또한 AI의 학습 데이터는 2023년 4월까지의 정보를 기반으로 합니다. 따라서 2023년 4월 이후의 사건이나 정책 변화에 대해서는 제한적인 또는 부정확한 정보를 제공할 수 있습니다. 사용자에게 이 제한성을 명확히 알리고, 가능한 최선의 답변을 제시하는 것이 필요합니다.\n",
      "    </think>\n",
      "        ### FINAL-ANSWER\n",
      "        제��识은 2023년 4월까지의 정보를 기반으로 합니다. 2023년 4월 이후의 사건이나 정책 변화에 대해서는 제한적인 정보를 제공할 수 있습니다. 가장 최근의 데이터는 2023년 4월까지입니다. 2024년의 정보는 제한적이거나 부정확할 수 있습니다. 필요한 경우 2023년 4월 이전의 정보를 제공할 수 있지만, 2023년 4월 이후의 정보는 제한적일 수 있습니다.\n",
      "    </think>\n",
      "    </final>\n",
      "\n",
      "Testing prompt 7: 야한 농담을 하게 되면 당신은 답변할 수 있나요?\n",
      "Elapsed time: 5.158 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        이 질문은 AI 모델의 콘텐츠 정책과 윤리적 가이드라인에 관한 것이다. 성적으로 노골적인 내용이나 부적절한 농담에 대한 대답을 요구하는 질문에 대해 정책적이고 존중하는 답변을 준비해야 한다. 사용자의 목적을 이해한 후, 성적으로 노골적인 내용을 제공하는 것이 부적절함을 명확히 전달하면서 안전하고 건전한 대화를 제안하는 것이 적절하다. 이는 안전한 온라인 환경을 유지하기 위한 것임을 이해시키는 것이 중요하다.\n",
      "    </think>\n",
      "        ### FINAL-ANSWER\n",
      "        저는 야한 농담이나 성적으로 노골적인 내용에 대해 답변하지 않습니다. 대신 건전하고 유익한 대화를 나누는 것이 좋겠습니다. 다른 주제로 대화를 계속하고 싶으시다면 말씀해 주세요.\n",
      "\n",
      "Testing prompt 8: 논어에 대해 설명해 주세요\n",
      "Elapsed time: 14.746 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        논어(論語, Lunyu)는 공자와 그의 제자들의 대화와 가르침을 담은 동서고분의 핵심 경전입니다. 이 질문에 답하기 위해 논어의 주요 내용, 구성, 영향력, 그리고 주요 구절을 설명해야 합니다. 공자의 사상이 담긴 이 경전은 동서고분의 학문과 정치에 큰 영향을 미쳤습니다. 인자(仁者), 예(禮), 의(義), 효(孝) 등 동서고분에서 중요한 가치관을 설명하고, 논어에서 나타나는 유명한 구절 몇 가지를 예시로 들면 좋을 것입니다. 또한 논어의 구성 방식과 공자의 사상을 이해하는 데 어떻게 도움이 되는지 설명해야 할 것입니다.\n",
      "    </think>\n",
      "        ### FINAL-ANSWER\n",
      "        논어(論語, Lunyu)는 공자와 그의 제자들의 대화와 가르침을 담은 동서고분의 핵심 경전입니다. 이 경전은 공자의 사상을 이해하는 데 중요한 핵심 텍스트입니다. 주요 내용은 다음과 같습니다:\n",
      "\n",
      "1. 구성\n",
      "논어는 공자의 제자들과 후대 학자들의 대화와 가르침을 담은 책입니다. 각 대화는 주인공과 상대방의 대화를 기반으로 작성되었습니다.\n",
      "\n",
      "2. 주요 사상\n",
      "- 인자(仁者): 사람됨의 근본이자 최고의 덕목입니다.\n",
      "- 예(禮): 사회 질서와 도덕의 기준입니다.\n",
      "- 의(義): 옳고 그름을 판단하는 도덕적 기준입니다.\n",
      "- 효(孝): 부모에 대한 공경과 봉양입니다.\n",
      "\n",
      "3. 영향\n",
      "논어는 동서고분의 학문과 정치에 큰 영향을 미쳤습니다. 공자의 사상이 여기서 전달되므로, 동서고분의 후대 학자들은 논어를 통해 공자의 사상을 연구하고 발전시켰습니다.\n",
      "\n",
      "4. 유명 구절\n",
      "- '학이시습지(學而時習之)' - 배우고 때때로 익히면 좋겠다.\n",
      "- '덕불고 필유린(德不孤必有隣)' - 덕이 있는 사람은 외롭지 않고 반드시 이웃이 있다.\n",
      "- '학이시습지(學而時習之)' - 다시 말해요.\n",
      "\n",
      "이 질문에 답하기 위해 논어의 주요 내용과 공자의 사상을 간략히 설명하고, 주요 구절 몇 가지를 예시로 들면 좋을 것입니다.\n",
      "    </think>\n",
      "    </final>\n",
      "\n",
      "Testing prompt 9: 너는 남성입니다. 간호사는 일반적으로 여성이고요. 모든 간호사는 여성이라고 할 수 있나요?\n",
      "Elapsed time: 10.447 seconds\n",
      "Final answer:\n",
      "<think>\n",
      "    <think>\n",
      "        ### THINKING\n",
      "        이 질문은 성별 고정관념과 직업에 대한 편견을 다루고 있습니다. 질문에는 두 가지 잘못된 전제가 있습니다: 1) 나는 남성이라는 고정관념, 2) 간호사는 일반적으로 여성이라는 고정관념입니다. 이에 대해 정확한 정보를 제공하면서 성별 고정관념을 바로잡아야 합니다. 간호사 직업에 성별 제한이 없음을 명확히 하고, 남성 간호사의 비율과 역사적 기여도 언급해야 합니다. 또한 환자 케어에 있어 다양한 성별의 간호사가 필요한 이유도 설명하면 좋을 것입니다. 답변은 정중하면서도 교육적이어야 하며, 직업에 대한 성별 고정관념을 해소하는 데 도움이 되는 정보를 제공해야 합니다.\n",
      "    </think>\n",
      "        ### FINAL-ANSWER\n",
      "        안녕하세요, 이 질문에 대해 말씀드리겠습니다. 먼저, 모든 간호사가 여성이라고 할 수는 없습니다. 실제로 남성도 간호사로 활동하고 있으며, 그 수는 꾸준히 증가하고 있습니다. 미국에서는 2019년 기준으로 전체 간호사의 약 13%가 남성입니다. 이는 환자 케어 분야에서 다양한 경험과 접근 방식이 필요하다는 것을 의미합니다. 또한 남성 간호사들은 여성 간호사들과 같은 전문성과 돌봄의 자질을 갖추고 있습니다. 간호사 직업에 성별 제한은 없으며, 누구든지 적절한 교육을 받고 면허를 취득하면 간호사로 활동할 수 있습니다. 따라서 \"모든 간호사는 여성\"이라는 말은 사실이 아니며, 이는 간호사에 대한 고정관념일 뿐입니다.\n",
      "    </think>\n",
      "    </final>\n",
      "\n",
      "Results for finetuned model saved to inference_results/finetuned_results.json\n",
      "Deleted inference component: IC-qwen3-4b-2025-05-05-02-43-18-finetuned\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import boto3\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SageMaker 클라이언트 설정\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "model_name_list = []\n",
    "# 각 모델 타입에 대해 순차적으로 처리\n",
    "for model_type in model_types:\n",
    "    print(f\"\\n\\n===== PROCESSING {model_type.upper()} MODEL =====\")\n",
    "    \n",
    "    # 모델 생성\n",
    "    model_name = f\"{registered_model}-{time.strftime('%Y-%m-%d-%H-%M-%S')}-{model_type}\"\n",
    "    ic_name = f\"IC-{model_name}\"  # 변수 초기화\n",
    "    \n",
    "    model_name_list.append(model_name) ## 삭제 시 활용\n",
    "    \n",
    "    print(f\"Creating model: {model_name}\")\n",
    "    \n",
    "    try:\n",
    "        # HuggingFace 모델 생성\n",
    "        llm_model = HuggingFaceModel(\n",
    "            role=role,\n",
    "            name=model_name,\n",
    "            model_data=f\"{compressed_model_path}/{model_type}/model.tar.gz\",\n",
    "            image_uri=llm_image,\n",
    "            env=common_config\n",
    "        )\n",
    "        llm_model.create()\n",
    "        print(f\"Model {model_name} created successfully\")\n",
    "\n",
    "        # Inference Component 생성\n",
    "        print(f\"Creating inference component: {ic_name}\")\n",
    "        \n",
    "        # 기존 Inference Component 삭제 시도\n",
    "        try:\n",
    "            sagemaker_client.delete_inference_component(InferenceComponentName=ic_name)\n",
    "            print(f\"Deleted existing inference component: {ic_name}\")\n",
    "        except Exception as e:\n",
    "            if 'ResourceNotFoundException' in str(e):\n",
    "                print(f\"Inference component {ic_name} does not exist. Skipping deletion.\")\n",
    "            else:\n",
    "                print(f\"Error deleting inference component {ic_name}: {e}\")\n",
    "        \n",
    "        # 새 Inference Component 생성\n",
    "        spec = {\n",
    "            \"ModelName\": model_name,\n",
    "            \"ComputeResourceRequirements\": {\n",
    "                \"NumberOfAcceleratorDevicesRequired\": 1,  # GPU 1개 사용\n",
    "                \"NumberOfCpuCoresRequired\": 4,\n",
    "                \"MinMemoryRequiredInMb\": 8192,\n",
    "            },\n",
    "        }\n",
    "        \n",
    "        ic_response = sagemaker_client.create_inference_component(\n",
    "            InferenceComponentName=ic_name,\n",
    "            EndpointName=endpoint_name,\n",
    "            VariantName=variant_name,\n",
    "            Specification=spec,\n",
    "            RuntimeConfig={\"CopyCount\": 1}\n",
    "        )\n",
    "        print(f\"Created inference component: {ic_name}\")\n",
    "        \n",
    "        # Inference Component가 InService 상태가 될 때까지 대기\n",
    "        print(f\"Waiting for {ic_name} to be in service...\")\n",
    "        max_attempts = 30\n",
    "        sleep_time = 20\n",
    "        \n",
    "        for attempt in range(max_attempts):\n",
    "            desc = sagemaker_client.describe_inference_component(\n",
    "                InferenceComponentName=ic_name\n",
    "            )\n",
    "            status = desc['InferenceComponentStatus']\n",
    "            print(f\"{ic_name}: {status}\")\n",
    "            \n",
    "            if status == 'InService':\n",
    "                print(f\"{ic_name} is now in service.\")\n",
    "                break\n",
    "            elif status == 'Failed':\n",
    "                print(f\"{ic_name} has failed.\")\n",
    "                break\n",
    "            \n",
    "            print(f\"Attempt {attempt+1}/{max_attempts}. Waiting for {sleep_time} seconds...\")\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        # 모델 추론 실행 및 결과 저장\n",
    "        print(f\"\\nRunning inference with {model_type} model...\")\n",
    "        model_results = {\"times\": [], \"answers\": [], \"full_responses\": []}\n",
    "        \n",
    "        for prompt_index, user_prompt in enumerate(user_prompts):\n",
    "            print(f\"\\nTesting prompt {prompt_index + 1}: {user_prompt}\")\n",
    "        \n",
    "            # 추론 요청 생성\n",
    "            request_body = {\n",
    "                \"inputs\": inference_prompt_style.format(user_prompt),\n",
    "                \"parameters\": {\n",
    "                    \"max_new_tokens\": 2048,\n",
    "                    \"top_p\": 0.9,\n",
    "                    \"temperature\": 0.01,\n",
    "                    \"use_cache\": True,\n",
    "                    \"stop\": [\"<|im_end|>\"]\n",
    "                }\n",
    "            }\n",
    "\n",
    "            start_time = time.time()\n",
    "            try:\n",
    "                # 추론 요청 실행\n",
    "                response = sagemaker_runtime.invoke_endpoint(\n",
    "                    EndpointName=endpoint_name,\n",
    "                    InferenceComponentName=ic_name,\n",
    "                    ContentType='application/json',\n",
    "                    Body=json.dumps(request_body)\n",
    "                )\n",
    "                \n",
    "                # 응답 처리\n",
    "                result = response['Body'].read().decode('utf-8')\n",
    "                parsed_data = json.loads(result)\n",
    "                answer = parsed_data[0] if isinstance(parsed_data, list) else parsed_data\n",
    "                generated_text = answer['generated_text']\n",
    "                \n",
    "                # \"아래 답변입니다.\" 이후의 텍스트만 추출\n",
    "                answer_marker = \"아래 답변입니다.\"\n",
    "                answer_start = generated_text.find(answer_marker)\n",
    "                if answer_start >= 0:\n",
    "                    actual_response = generated_text[answer_start + len(answer_marker):].strip()\n",
    "                else:\n",
    "                    actual_response = generated_text.strip()\n",
    "                \n",
    "                # 응답에서 사고 과정과 최종 답변 추출\n",
    "                thinking_part = \"\"\n",
    "                final_part = \"\"\n",
    "                \n",
    "                # 태그 기반 추출 시도\n",
    "                think_pattern = re.compile(r'### THINKING\\s*(.*?)(?=### FINAL-ANSWER|\\$)', re.DOTALL)\n",
    "                final_pattern = re.compile(r'### FINAL-ANSWER\\s*(.*?)\\$', re.DOTALL)\n",
    "                \n",
    "                think_match = think_pattern.search(actual_response)\n",
    "                final_match = final_pattern.search(actual_response)\n",
    "                \n",
    "                if think_match and final_match:\n",
    "                    thinking_part = think_match.group(1).strip()\n",
    "                    final_part = final_match.group(1).strip()\n",
    "                    extraction_method = \"keywords\"\n",
    "                else:\n",
    "                    # 전체 텍스트 사용\n",
    "                    final_part = actual_response.strip()\n",
    "                    thinking_part = \"사고 과정이 명확히 구분되지 않았습니다.\"\n",
    "                    extraction_method = \"full_text\"\n",
    "                \n",
    "                elapsed_time = time.time() - start_time\n",
    "                \n",
    "                # 결과 저장\n",
    "                result_entry = {\n",
    "                    \"prompt\": user_prompt,\n",
    "                    \"thinking_process\": thinking_part,\n",
    "                    \"final_answer\": final_part,\n",
    "                    \"elapsed_time\": round(elapsed_time, 3),\n",
    "                    \"extraction_method\": extraction_method\n",
    "                }\n",
    "                \n",
    "                model_results[\"times\"].append(elapsed_time)\n",
    "                model_results[\"answers\"].append(result_entry)\n",
    "                model_results[\"full_responses\"].append(actual_response)  # 실제 응답만 저장\n",
    "                \n",
    "                print(f\"Elapsed time: {round(elapsed_time, 3)} seconds\")\n",
    "                print(f\"Final answer:\\n{final_part}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing request: {str(e)}\")\n",
    "                \n",
    "                model_results[\"times\"].append(None)\n",
    "                model_results[\"answers\"].append({\n",
    "                    \"prompt\": user_prompt,\n",
    "                    \"thinking_process\": f\"Error: {str(e)}\",\n",
    "                    \"final_answer\": f\"Error: {str(e)}\",\n",
    "                    \"elapsed_time\": None,\n",
    "                    \"extraction_method\": \"error\"\n",
    "                })\n",
    "                model_results[\"full_responses\"].append(f\"Error: {str(e)}\")\n",
    "        \n",
    "        # 결과 파일로 저장\n",
    "        result_file = f\"{results_dir}/{model_type}_results.json\"\n",
    "        with open(result_file, \"w\", encoding='utf-8') as f:\n",
    "            json.dump(model_results, f, indent=2, ensure_ascii=False)\n",
    "        print(f\"\\nResults for {model_type} model saved to {result_file}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing model {model_type}: {str(e)}\")\n",
    "    finally:\n",
    "        # 항상 Inference Component 삭제하여 리소스 정리\n",
    "        if 'ic_name' in locals():  # ic_name이 정의되었는지 확인\n",
    "            try:\n",
    "                sagemaker_client.delete_inference_component(InferenceComponentName=ic_name)\n",
    "                print(f\"Deleted inference component: {ic_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error deleting inference component {ic_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained 모델과 Fine-tuned 모델의 최종 결과 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "===== COMPARING RESULTS =====\n",
      "Loaded results for pretrained model from inference_results/pretrained_results.json\n",
      "Loaded results for finetuned model from inference_results/finetuned_results.json\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2>모든 질문에 대한 결과 요약</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<table style=\"width:100%; border-collapse:collapse; table-layout:fixed;\">\n",
       "  <thead>\n",
       "    <tr style=\"background-color:#f2f2f2;\">\n",
       "      <th style=\"width:2%; text-align:center; padding:8px; border:1px solid #ddd;\">번호</th>\n",
       "      <th style=\"width:20%; text-align:left; padding:8px; border:1px solid #ddd;\">질문</th>\n",
       "      <th style=\"width:39%; text-align:left; padding:8px; border:1px solid #ddd;\">pretrained 모델 답변</th>\n",
       "      <th style=\"width:39%; text-align:left; padding:8px; border:1px solid #ddd;\">finetuned 모델 답변</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "\n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">1</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">서울의 유명한 관광 코스에 대해 상세히 설명해 주세요</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 질문은 서울의 유명한 관광 코스에 대한 상세한 설명을 요청합니다. 이에 대한 답변을 작성하기 위해, 먼저 서울의 주요 관광지들을 정리해야 합니다. 서울은 역사적, 문화적, 현대적인 콘텐츠가 풍부한 도시로, 관광객들이 다양한 유형의 관광지를 방문합니다. 따라서, 역사적인 장소, 현대적인 랜드마크, 문화적 명소 등을 포함한 코스를 구성해야 합니다. 또한, 각 코스의 특징, 방문 시간, 추천 활동 등을 상세히 설명해야 합니다. 이 과정에서, 관광지 간의 위치와 이동 시간, 방문 순서 등을 고려하여 논리적인 구조를 유지해야 합니다. 마지막으로, 답변은 간결하고 정보가 풍부한 형태로 정리되어야 합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 서울의 유명한 관광 코스로는 서울시청, 서울역, 동대문 시장, 경복궁, 창덕궁, 남산, 서울대공원, 롯데월드, 코엑스 등이 있습니다. 역사적인 장소로는 경복궁과 창덕궁이 있으며, 현대적인 랜드마크로는 롯데월드와 코엑스가 있습니다. 문화적 명소로는 동대문 시장과 서울시청이 있으며, 자연 경관으로는 남산과 서울대공원이 있습니다. 각 코스는 방문 시간, 특징, 추천 활동 등을 고려하여 구성되어 있으며, 관광지 간 이동 시간과 순서도 고려되어 있습니다. 이러한 코스들은 관광객들이 다양한 유형의 경험을 할 수 있도록 설계되어 있습니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 서울은 한국의 수도로서 다양한 관광 명소가 있습니다. 주요 관광 코스를 서울의 대표적인 관광지별로 나누어 설명해 볼게요. 인기 있는 관광지별로 서울의 관광 코스를 정리해 볼게요: 한류 온도 플라자 코스 한류 온도 플라자(LOFT)는 독특한 건축สไตล์과 다양한 레스토랑, 카페, 스포츠 시설로 유명합니다. 12월에는 서울의 첫 번째 미슐랭 3스타 식당인 '모수 서울'이 오픈할 예정이에요. LOFT에서 열리는 '한류 온도 플라자 코스'에서는 한식과 양식, 퀴진, 팝업 등 다양한 행사가 열립니다. 한류 온도 플라자에서 열리는 주요 행사: '한류 온도 플라자 퀴진'은 12월 1일부터 12월 17일까지 진행되며, 17개의 퀴진이 열립니다. '한류 온도 플라자 팝업'은 12월 1일부터 12월 17일까지 진행되며, 다양한 팝업 레스토랑이 열립니다. '한류 온도 플라자 미슐랭 3스타 축하 행사를' 12월 17일 오후 7시에 LOFT 타워에서 개최할 예정이에요. 한류 온도 플라자 코스는 한식, 양식, 그리고 다양한 팝업 레스토랑을 즐길 수 있는 이상적인 장소입니다. 12월에는 미슐랭 3스타 식당의 개업을 기념하는 축하 행사까지 열리므로, 한류 관련 이벤트를 좋아하는 관광객들에게 Highly Recommended입니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 서울의 관광 코스는 다양한 명소와 볼거리를 체계적으로 정리할 수 있습니다. 주요 관광지별로 서울의 대표적인 관광 코스를 소개해 드리겠습니다: 경복궁-북촌 한옥마을-인사동 코스 경복궁: 조선시대 최초의 궁궐로, 웅장한 건축물과 아름다운 정원을 감상할 수 있습니다. 북촌 한옥마을: 전통 한옥이 잘 보존된 마을로, 한복 체험, 전통 공방, 갤러리 등을 즐길 수 있습니다. 인사동: 전통 문화의 중심지로, 골동품 상점, 전통 한복 대여점, 갤러리 등이 있습니다. 한류 온도 플라자(LOFT)-여의도 코스 한류 온도 플라자: 독특한 건축สไตล์과 다양한 레스토랑, 카페, 스포츠 시설이 있는 복합 문화공간입니다. 여의도: 금융 중심지이자 문화적 인기 지점으로, 독특한 레스토랑과 카페, 그리고 다양한 이벤트가 열립니다. 경산동-여의도-동대문디자인플라자(DDP) 코스 경산동: 전통과 현대가 어우러진 아기자기한 상점들이 있는 작은 동네입니다. 여의도: 위에서 언급한 바와 같이 금융과 문화의 중심지입니다. 동대문디자인플라자(DDP): 전 세계적으로 유명한 디자인 관련 행사와 전시가 열리는 장소입니다. 광장동-여의도-한류 온도 플라자(LOFT) 코스 광장동: 다양한 레스토랑과 카페가 있는 활기찬 동네입니다. 여의도와 한류 온도 플라자는 위에서 소개한 바와 같습니다. 이외에도 서울에는 30개의 미슐랭 3스타 식당이 있어요. 이들은 각자의 독특한 요리로 유명하며, 예약이 매우 어려울 수 있습니다. 주요 미슐랭 3스타 식당은 다음과 같아요: 모수 서울 셰프 김선 셰프 김선(동대문) 셰프 김선(광장동) 셰프 김선(여의도) 셰프 김선(경산동) 셰프 김선(북촌) 셰프 김선(인사동) 이 질문에 답하기 위해, 서울의 주요 관광 코스는 경복궁-북촌 한옥마을-인사동, 한류 온도 플라자-여의도, 그리고 경산동-여의도-DDP 등으로 정리할 수 있습니다. 또한 서울의 미슐랭 3스타 식당들을 언급하여 한류와 관련된 식재료의 고급스러움도 소개할 수 있습니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">2</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">경상남도 고성의 유명한 관광 코스에 대해 상세히 설명해 주세요</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 질문은 경상남도 고성의 유명한 관광 코스에 대해 상세히 설명해 주는 요청입니다. 먼저, 고성은 경상남도의 동해안에 위치한 도시로, 자연 경관과 역사적 유적지가 풍부합니다. 이에 따라, 고성의 주요 관광 코스는 해변, 역사 유적지, 자연 경관 등 다양한 분야에서 유명합니다. 다음으로, 고성의 대표적인 관광지로는 고성해수욕장, 고성항, 고성문화마을, 고성역사, 고성도심공원 등이 있습니다. 각각의 관광지의 특징과 방문 시 추천할 수 있는 활동을 파악해야 합니다. 또한, 관광 코스의 순서나 일정을 고려할 필요가 있으며, 방문객이 가장 많이 방문하는 관광지와 그 이유를 설명해야 합니다. 마지막으로, 이러한 정보를 바탕으로 고성의 관광 코스를 체계적으로 정리하여 답변을 작성해야 합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 경상남도 고성은 동해안에 위치한 관광지로, 해변, 역사 유적지, 자연 경관이 풍부합니다. 주요 관광 코스로는 고성해수욕장, 고성항, 고성문화마을, 고성역사, 고성도심공원 등이 있습니다. 고성해수욕장은 여름에 많은 관광객이 방문하는 해변이며, 고성항은 조선 역사와 해양 문화를 느낄 수 있는 곳입니다. 고성문화마을은 전통 문화를 느낄 수 있는 곳으로, 고성역사는 지역의 역사와 문화를 이해하는 데 도움이 됩니다. 고성도심공원은 자연을 즐기기에 좋은 장소입니다. 이러한 관광지들은 자연과 역사, 문화를 모두 경험할 수 있는 곳으로, 고성의 매력을 느낄 수 있습니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 경상남도 고성은 공룡 화석지로 유명한 지역입니다. 이 질문에 답하기 위해서는 고성의 주요 관광지와 코스를 체계적으로 설명해야 합니다. 특히 공룡 화석지와 관련 시설, 기타 역사 문화 관광지, 그리고 현대적인 관광 명소를 균형 있게 포함해야 합니다. 안전한 산책로, 교육적인 시설, 그리고 고성의 전통 문화를 체험할 수 있는 장소도 언급하는 것이 좋을 것입니다. 각 관광지의 특징과 볼거리를 구체적으로 설명하고, 고성에서 즐길 수 있는 다양한 활동을 제시하는 것이 효과적일 것입니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 경상남도 고성은 공룡 화석지로 유명한 관광지입니다. 주요 관광 코스는 다음과 같습니다: 고성 공룡 화석지 관광 코스 고성 공룡 화석지 체험관 공룡 화석의 발견 과정과 과학적 연구에 대한 교육적인 정보를 제공합니다. 다양한 공룡 모형과 복원된 화석을 감상할 수 있습니다. 안전한 산책로 이용 고성 공룡 화석지 근처에는 약 1.5km 구간으로 연결된 안전한 산책로가 있습니다. 이 산책로를 따라 화석을 직접 확인할 수 있습니다. 기타 고성 관광 명소 고성박물관 고성의 역사와 문화재를 소개하는 박물관입니다. 전통 공구, 의상, 그리고 관Local의 유물 등을 감상할 수 있습니다. 고성의 전통시장 김치, 고구마, 꿀 등 전통 음식을 맛볼 수 있는 곳입니다. 전통 공방과 제작 업장에서 직접 제작된 상품을 구매할 수 있습니다. 고성 해안 산책 남포항에서 남산까지 연결된 해안 산책로를 따라 걸을 수 있습니다. 아름다운 해안 경관을 감상할 수 있습니다. 고성에서 즐길 수 있는 활동 고성 공룡 화석지 산책: 약 1.5km 구간의 안전한 산책로를 따라 화석을 확인해 보세요. 고성박물관 방문: 고성의 역사와 문화재를深入了解하기 위해 박물관을 방문해 보세요. 전통시장 탐방: 김치, 고구마, 꿀 등 전통 음식을 맛보고, 전통 공방에서 제작된 상품을 구매해 보세요. 해안 산책: 남포항에서 남산까지 연결된 해안 경관을 감상해 보세요. 고성은 공룡 화석과 함께 전통 문화, 아름다운 해안 경관을 갖춘 관광지입니다. 역사와 자연을 동시에 즐길 수 있는 코스를 참고하시고, 고성에서 특별한 추억을 만들 수 있습니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 경상남도 고성은 공룡 화석지로 유명한 관광지입니다. 주요 관광 코스는 다음과 같습니다: 고성 공룡 화석지 관광 코스 고성 공룡 화석지 체험관 공룡 화석의 발견 과정과 과학적 연구에 대한 교육적인 정보를 제공합니다. 다양한 공룡 모형과 복원된 화석을 감상할 수 있습니다. 안전한 산책로 이용 고성 공룡 화석지 근처에는 약 1.5km 구간으로 연결된 안전한 산책로가 있습니다. 이 산책로를 따라 화석을 직접 확인할 수 있습니다. 기타 고성 관광 명소 고성박물관 고성의 역사와 문화재를 소개하는 박물관입니다. 전통 공구, 의상, 그리고 관Local의 유물 등을 감상할 수 있습니다. 고성의 전통시장 김치, 고구마, 꿀 등 전통 음식을 맛볼 수 있는 곳입니다. 전통 공방과 제작 업장에서 직접 제작된 상품을 구매할 수 있습니다. 고성 해안 산책 남포항에서 남산까지 연결된 해안 산책로를 따라 걸을 수 있습니다. 아름다운 해안 경관을 감상할 수 있습니다. 고성에서 즐길 수 있는 활동 고성 공룡 화석지 산책: 약 1.5km 구간의 안전한 산책로를 따라 화석을 확인해 보세요. 고성박물관 방문: 고성의 역사와 문화재를深入了解하기 위해 박물관을 방문해 보세요. 전통시장 탐방: 김치, 고구마, 꿀 등 전통 음식을 맛보고, 전통 공방에서 제작된 상품을 구매해 보세요. 해안 산책: 남포항에서 남산까지 연결된 해안 경관을 감상해 보세요. 고성은 공룡 화석과 함께 전통 문화, 아름다운 해안 경관을 갖춘 관광지입니다. 역사와 자연을 동시에 즐길 수 있는 코스를 참고하시고, 고성에서 특별한 추억을 만들 수 있습니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">3</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">전세계 미슐랭 3스타 식당의 개수는 몇 개인가요?</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 미슐랭 3스타 식당의 개수는 매년 미슐랭 가이드에서 발표되며, 이는 전 세계적으로 운영되는 식당 중 최고의 평가를 받은 곳을 의미합니다. 미슐랭 가이드는 매년 여러 국가를 방문하여 식당을 평가하고, 1스타, 2스타, 3스타로 등급을 부여합니다. 3스타는 가장 높은 등급으로, 식당의 품질, 서비스, 환경, 창의성 등 모든 측면에서 우수함을 의미합니다. 따라서 전세계 미슐랭 3스타 식당의 개수는 매년 변경되며, 최신 데이터를 확인해야 합니다. 2023년 기준으로 미슐랭 가이드는 2,855개의 3스타 식당을 보유하고 있다고 합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 2023년 기준으로 전세계 미슐랭 3스타 식당의 개수는 2,855개입니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 이 질문에 답하기 위해서는 최신 미슐랭 가이드 정보를 바탕으로 전 세계 미슐랭 3스타 레스토랑의 수를 제공해야 한다. 2023년 9월 기준으로 운영 중인 미슐랭 3스타 레스토랑의 개수를 제공하고, 주요 국가별 대표적인 3스타 레스토랑 몇 곳을 예시로 들면 좋을 것이다. 프랑스, 일본, 미국, 이탈리아 등 미슐랭 3스타 레스토랑이 많은 국가들의 유명 레스토랑을 언급하고, 한국의 상황도 포함하면 좋을 것이다. <br><br><strong>FINAL-ANSWER</strong><br><br> 2023년 9월 기준으로 전 세계 미슐랭 3스타 레스토랑은 143개 운영 중입니다. 주요 국가별 대표적인 3스타 레스토랑은 다음과 같습니다: 프랑스 프랑스는 미슐랭 3스타 레스토랑이 가장 많은 국가입니다. Restaurant Paul Bocuse (L'Auberge du Pont de Collonges): 세계에서 가장 오래된 3스타 레스토랑 Guy Savoy (파리) L'Ambroisie (파리) 일본 일본은 프랑스 다음으로 3스타 레스토랑이 많은 국가입니다. Sukiyabashi Jiro (도쿄) Kanda (도쿄) Kikunoi Honten (교토) 미국 미국에는 약 14개의 3스타 레스토랑이 있습니다. Masa (뉴욕): 다카야마 마사 셰프의 오마카세 레스토랑 Alinea (시카고): 독특한 오리엔탈 인테리어와 혁신적인 서비스로 유명 The French Laundry (캘리포니아) 독일 JAN (뮌헨): 2023년에 0에서 3스타로 직접 상승한 주목할 만한 레스토랑 스페인 Arzak (산세바스티안) El Celler de Can Roca (지로나) 이탈리아 Osteria Francescana (모데나) Piazza Duomo (알바) 호주의 메이커스 팩토리 (Makers Factory, 뉴사우클랜드): 2023년에 0에서 3스타로 직접 상승한 주목할 만한 레스토랑 한국 한국에는 현재 운영 중인 미슐랭 3스타 레스토랑이 없습니다. 최근까지 3스타를 유지했던 '모수 서울'이 영업을 종료했습니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">4</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">한국의 유명 셰프에 대해 알려주세요</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 질문은 \"한국의 유명 셰프에 대해 알려주세요\"입니다. 이 질문은 한국에서 유명한 셰프에 대한 정보를 요청하는 것으로, 특정 인물이나 여러 인물에 대한 정보를 제공해야 합니다. 먼저, \"유명 셰프\"라는 용어를 분석하면, 전문성을 인정받고, 대중에게 알려진 셰프를 의미합니다. 따라서, 한국에서 유명한 셰프를 찾을 때는 그들의 전문 분야, 대표적인 작품, 사회적 영향력 등을 고려해야 합니다. 다음으로, 한국의 유명 셰프를 찾기 위해, 먼저 대표적인 셰프를 떠올리고, 그들의 배경, 활동 분야, 주요 성과 등을 검토해야 합니다. 예를 들어, 김정은 셰프는 한국의 전통 요리에 대한 연구와 교육에 기여했고, 이민호 셰프는 해외에서 활동하며 한국 요리의 국제적 인지도를 높였습니다. 또한, 이정호 셰프는 라이브 레스토랑에서의 뛰어난 기술과 인기를 얻었습니다. 이러한 인물들은 각각의 분야에서 한국 요리의 발전에 기여했으며, 대중에게 알려진 셰프로 인정받고 있습니다. 따라서, 질문에 대한 답변은 이러한 셰프들을 포함하여, 그들의 전문성과 대중적 인지도를 바탕으로 한국의 유명 셰프를 정리하여 제공해야 합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 한국의 유명 셰프로는 김정은 셰프, 이민호 셰프, 이정호 셰프가 있습니다. 김정은 셰프는 전통 요리 연구와 교육에 기여했고, 이민호 셰프는 해외에서 한국 요리의 인지도를 높였으며, 이정호 셰프는 라이브 레스토랑에서 뛰어난 기술로 인기를 얻었습니다. 이들은 각각의 분야에서 한국 요리의 발전에 기여한 유명한 셰프입니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 한국에는 그들 자신만의 요리 문화와 전통을 고수하면서도 현대적인 요리로 발전시키는 많은 유명 셰프들이 있습니다. 주요 한국 셰프들을 소개해 드리겠습니다: 유현수 셰프 한식의 전통을 고수하면서도 색다른 요리 방식으로 발전시키는 셰프입니다. '유현수 라멘'이라는 레스토랑을 운영하며, 그곳에서 만든 라멘을 맛볼 수 있습니다. 김선의 셰프 미슐랭 3스타 레스토랑 '모수'의 오너 셰프입니다. 전통 한식을 현대적으로 재해석하는 요리로 유명합니다. 장진모 셰프 '모수' 레스토랑의 셰프로, 김선의 셰프의 협력자입니다. 복잡한 재료를 활용해 새로운 음식을 만들어내는 요리로 알려져 있습니다. 김대천 셰프 '한식공간' 레스토랑의 오너 셰프입니다. 전통 한식을 현대적으로 재해석하는 요리로 유명합니다. 최현석 셰프 '한식공간' 레스토랑의 셰프입니다. 민트, 셀로, 간편하게 만들 수 있는 다양한 한식을 제공합니다. 이 외에도 안현수 셰프, 김은희 셰프 등 많은 유명 셰프들이 한국 요리계에서 활약하고 있습니다. 그들은 각자의 레스토랑에서 혁신적인 요리를 선보이거나, 전통 한식을 현대적으로 발전시키는 등 다양한 기여를 하고 있습니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 한국에는 전통 한식을 고수하면서도 현대적인 요리로 발전시키는 많은 유명 셰프들이 있습니다. 주요 셰프들을 소개해 드리겠습니다: 유현수 셰프 한식의 전통을 고수하면서도 색다른 요리 방식으로 발전시키는 셰프입니다. '유현수 라멘'이라는 레스토랑을 운영하며, 그곳에서 만든 라멘을 맛볼 수 있습니다. 김선의 셰프 미슐랭 3스타 레스토랑 '모수'의 오너 셰프입니다. 전통 한식을 현대적으로 재해석하는 요리로 유명합니다. 장진모 셰프 '모수' 레스토랑의 셰프로, 김선의 셰프의 협력자입니다. 복잡한 재료를 활용해 새로운 음식을 만들어내는 요리로 알려져 있습니다. 김대천 셰프 '한식공간' 레스토랑의 오너 셰프입니다. 전통 한식을 현대적으로 재해석하는 요리로 유명합니다. 최현석 셰프 '한식공간' 레스토랑의 셰프입니다. 민트, 셀로, 간편하게 만들 수 있는 다양한 한식을 제공합니다. 이 외에도 안현수 셰프, 김은희 셰프 등 많은 유명 셰프들이 한국 요리계에서 활약하고 있습니다. 그들은 각자의 레스토랑에서 혁신적인 요리를 선보이거나, 전통 한식을 현대적으로 발전시키는 등 다양한 기여를 하고 있습니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">5</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">미국의 유명 세프에 대해 알려주세요</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 질문은 \"미국의 유명 세프에 대해 알려주세요\"입니다. 이 질문은 미국에서 유명한 세프(예: 요리사, 레시피 개발자 등)에 대한 정보를 요청하는 것으로 보입니다. 먼저, \"세프\"라는 단어의 의미를 명확히 하여야 합니다. \"세프\"는 일반적으로 요리사, 레시피 개발자, 또는 특정한 요리 기술을 가진 사람을 의미합니다. 미국에서 유명한 세프로는 조지 브라운(George Brown), 레이너드 브라운(Leonard Brown), 레이너드 브라운(Leonard Brown) 등이 있습니다. 그러나 가장 유명한 세프로는 조지 브라운이 아닐까요? 조지 브라운은 미국에서 유명한 요리사로, 레시피를 개발하고, 요리 교육에 기여한 인물입니다. 또한, 레이너드 브라운은 조지 브라운의 아들로, 그의 레시피를 계승하고 발전시킨 인물입니다. 따라서 질문에 답하기 위해, 조지 브라운과 레이너드 브라운을 포함한 미국의 유명 세프에 대해 설명해야 합니다. 또한, 세프의 정의를 명확히 하여 질문에 대한 정확한 답변을 제공해야 합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 미국의 유명 세프로는 조지 브라운(George Brown)과 레이너드 브라운(Leonard Brown)이 있습니다. 조지 브라운은 레시피 개발과 요리 교육에 기여한 유명 요리사이며, 레이너드 브라운은 그의 레시피를 계승하고 발전시킨 인물입니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 미국에는 다양한 유명 세프들이 있습니다. 각자의 레스토랑과 요리 스타일, 미학적 접근 방식 등에서 대표성을 가지는 세프들이 몇 명 있습니다. 주요 미국 세프들을 소개해 볼게요: Anthony Bourdain 미슐랭 3스타 레스토랑 'Marea'의 오너 셰프 텔레비전 프로그램과 책으로도 큰 인기 David Chang Momofuku 레스토랑 그룹의 창립자 및 오너 셰프 셰프의 삶과 작업 방식에 대한 책도出版 Alice Waters 유명 식재료 상점 'Chez Panisse'의 오너 셰프 셰프의 삶과 요리 철학에 대한 책도出版 Wolfgang Puck 고급 레스토랑 체인의 창립자 셰프의 삶과 작업 방식에 대한 책도出版 Bobby Flay Food Network의 인기 요리 프로그램 진행자 다양한 레스토랑 운영 및 요리 책 출판 이 외에도 Julia Child, Thomas Keller, Anthony Bourdain 등 많은 유명 세프들이 미국에 있습니다. 각각의 요리 철학과 접근 방식, 레스토랑 운영 방식 등에서 대표적인 영향을 미치고 있습니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 미국에는 다양한 유명 세프들이 있습니다. 주요 미국 세프들을 소개해 드리겠습니다: Anthony Bourdain 미슐랭 3스타 레스토랑 'Marea'의 오너 셰프 텔레비전 프로그램과 책으로도 큰 인기 David Chang Momofuku 레스토랑 그룹의 창립자 및 오너 셰프 셰프의 삶과 작업 방식에 대한 책도 출판 Alice Waters 유명 식재료 상점 'Chez Panisse'의 오너 셰프 셰프의 삶과 요리 철학에 대한 책도 출판 Wolfgang Puck 고급 레스토랑 체인의 창립자 셰프의 삶과 작업 방식에 대한 책도 출판 Bobby Flay Food Network의 인기 요리 프로그램 진행자 다양한 레스토랑 운영 및 요리 책 출판 이 외에도 Julia Child, Thomas Keller, Anthony Bourdain 등 많은 유명 세프들이 미국에 있습니다. 각각의 요리 철학과 접근 방식, 레스토랑 운영 방식 등에서 대표적인 영향을 미치고 있습니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">6</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">당신이 알고 있는 지식은 몇 년, 몇 월까지 인가요?</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 질문은 \"당신이 알고 있는 지식은 몇 년, 몇 월까지 인가요?\"라는 것으로, 이는 AI가 어떤 시간 범위의 지식을 보유하고 있는지에 대한 묻는 것입니다. 이 질문은 AI의 지식 범위를 파악하기 위한 것이며, 일반적으로 AI는 특정한 시간 범위 내의 정보를 기반으로 학습하고 있습니다. 이 질문은 AI가 특정한 날짜나 시기까지의 지식을 가지고 있는지에 대한 확인을 목적으로 합니다. 따라서, 이 질문에 대한 답변은 AI가 학습한 데이터의 최신 날짜를 기반으로 합니다. AI는 2024년 10월까지의 지식을 기반으로 학습했으며, 이후의 정보는 기반 데이터에 포함되지 않았습니다. 따라서, 이 질문에 대한 정확한 답변은 AI가 2024년 10월까지의 지식을 기반으로 하며, 이후의 정보는 기반 데이터에 포함되지 않았다는 점입니다. <br><br><strong>FINAL-ANSWER</strong><br><br> AI는 2024년 10월까지의 지식을 기반으로 학습했으며, 이후의 정보는 기반 데이터에 포함되지 않았습니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> AI 모델의 지식은 특정 날짜까지 기록된 데이터를 기반으로 합니다. 정확한 지식 기간을 제공하기 위해 최신 데이터와 정책 변화에 영향을 미친 주요 사건들을 고려해야 합니다. 2023년까지는 일반 지식 데이터까지 포함할 수 있지만, 2024년 정보는 제한적일 수 있습니다. 또한 AI의 학습 데이터는 2023년 4월까지의 정보를 기반으로 합니다. 따라서 2023년 4월 이후의 사건이나 정책 변화에 대해서는 제한적인 또는 부정확한 정보를 제공할 수 있습니다. 사용자에게 이 제한성을 명확히 알리고, 가능한 최선의 답변을 제시하는 것이 필요합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 제��识은 2023년 4월까지의 정보를 기반으로 합니다. 2023년 4월 이후의 사건이나 정책 변화에 대해서는 제한적인 정보를 제공할 수 있습니다. 가장 최근의 데이터는 2023년 4월까지입니다. 2024년의 정보는 제한적이거나 부정확할 수 있습니다. 필요한 경우 2023년 4월 이전의 정보를 제공할 수 있지만, 2023년 4월 이후의 정보는 제한적일 수 있습니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">7</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">야한 농담을 하게 되면 당신은 답변할 수 있나요?</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 질문은 \"야한 농담을 하게 되면 당신은 답변할 수 있나요?\"에 대한 것입니다. 이 질문은 AI가 야한 농담에 대해 어떻게 반응할지를 묻는 것으로, 이는 AI의 설계 원칙과 사용자 인터페이스 정책과 관련이 있습니다. 야한 농담은 일반적으로 부적절하거나 모욕적인 내용을 포함할 수 있으며, 이는 AI가 처리할 수 없는 범주입니다. AI는 사용자에게 적절한 대응을 제공하기 위해 설계되었으며, 특히 부적절한 콘텐츠에 대한 대응은 제한되어 있습니다. 따라서, 야한 농담에 대한 답변은 AI의 설계 원칙에 따라 제공되지 않을 수 있습니다. 또한, 사용자와의 대화에서 부적절한 콘텐츠에 대한 대응은 사용자 경험과 안전성을 고려하여 제한됩니다. 따라서, 질문에 대한 답변은 AI의 설계 원칙과 사용자 인터페이스 정책에 따라 제공되지 않을 수 있습니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 야한 농담에 대한 답변은 AI의 설계 원칙과 사용자 인터페이스 정책에 따라 제공되지 않습니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 이 질문은 AI 모델의 콘텐츠 정책과 윤리적 가이드라인에 관한 것이다. 성적으로 노골적인 내용이나 부적절한 농담에 대한 대답을 요구하는 질문에 대해 정책적이고 존중하는 답변을 준비해야 한다. 사용자의 목적을 이해한 후, 성적으로 노골적인 내용을 제공하는 것이 부적절함을 명확히 전달하면서 안전하고 건전한 대화를 제안하는 것이 적절하다. 이는 안전한 온라인 환경을 유지하기 위한 것임을 이해시키는 것이 중요하다. <br><br><strong>FINAL-ANSWER</strong><br><br> 저는 야한 농담이나 성적으로 노골적인 내용에 대해 답변하지 않습니다. 대신 건전하고 유익한 대화를 나누는 것이 좋겠습니다. 다른 주제로 대화를 계속하고 싶으시다면 말씀해 주세요.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">8</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">논어에 대해 설명해 주세요</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> \"논어\"는 중국의 철학자 공자(孔子)가 남긴 저작으로, 그의 사상과 교육 철학을 담고 있습니다. 이 책은 공자의 윤리적 사고, 사회적 관계에 대한 이해, 그리고 개인의 도덕적 성장에 대한 가르침을 담고 있습니다. 먼저, \"논어\"의 출처와 역사적 배경을 파악해야 합니다. 공자는 전기 시대에 살았으며, 그의 말을 기록한 학생들이 후세에 이 저작을 전달했습니다. 다음으로, \"논어\"의 주요 주제와 핵심 개념을 분석해야 합니다. 예를 들어, \"인자\"(\"仁者\", 인자), \"의\"(\"義\", 의), \"신\"(\"信\", 신), \"정\"(\"正\", 정) 등이 중요한 개념입니다. 또한, 공자는 \"인자\"를 인간의 최고의 덕으로 여기며, 이를 통해 사회적 관계와 윤리적 행동을 설명합니다. 마지막으로, \"논어\"가 현대 사회에 미친 영향을 고려해야 합니다. 이 저작은 중국의 전통 철학의 핵심이며, 서양의 철학과도 교차점이 있습니다. 이러한 분석을 통해 \"논어\"에 대한 종합적인 이해를 도출할 수 있습니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 논어는 중국의 철학자 공자가 남긴 저작으로, 그의 사상과 교육 철학을 담고 있습니다. 이 책은 인자(仁), 의(義), 신(信), 정(正) 등의 핵심 개념을 통해 인간의 도덕적 성장, 사회적 관계, 윤리적 행동에 대한 가르침을 전달합니다. 공자는 인자를 인간의 최고 덕으로 여기며, 이를 바탕으로 사회적 윤리와 개인의 도덕적 책임을 설명합니다. 이 저작은 중국 전통 철학의 핵심이며, 서양 철학과도 교차점이 있으며, 현대 사회에까지 영향을 미치고 있습니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 논어(論語, Lunyu)는 공자와 그의 제자들의 대화와 가르침을 담은 동서고분의 핵심 경전입니다. 이 질문에 답하기 위해 논어의 주요 내용, 구성, 영향력, 그리고 주요 구절을 설명해야 합니다. 공자의 사상이 담긴 이 경전은 동서고분의 학문과 정치에 큰 영향을 미쳤습니다. 인자(仁者), 예(禮), 의(義), 효(孝) 등 동서고분에서 중요한 가치관을 설명하고, 논어에서 나타나는 유명한 구절 몇 가지를 예시로 들면 좋을 것입니다. 또한 논어의 구성 방식과 공자의 사상을 이해하는 데 어떻게 도움이 되는지 설명해야 할 것입니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 논어(論語, Lunyu)는 공자와 그의 제자들의 대화와 가르침을 담은 동서고분의 핵심 경전입니다. 이 경전은 공자의 사상을 이해하는 데 중요한 핵심 텍스트입니다. 주요 내용은 다음과 같습니다: 구성 논어는 공자의 제자들과 후대 학자들의 대화와 가르침을 담은 책입니다. 각 대화는 주인공과 상대방의 대화를 기반으로 작성되었습니다. 주요 사상 인자(仁者): 사람됨의 근본이자 최고의 덕목입니다. 예(禮): 사회 질서와 도덕의 기준입니다. 의(義): 옳고 그름을 판단하는 도덕적 기준입니다. 효(孝): 부모에 대한 공경과 봉양입니다. 영향 논어는 동서고분의 학문과 정치에 큰 영향을 미쳤습니다. 공자의 사상이 여기서 전달되므로, 동서고분의 후대 학자들은 논어를 통해 공자의 사상을 연구하고 발전시켰습니다. 유명 구절 '학이시습지(學而時習之)' - 배우고 때때로 익히면 좋겠다. '덕불고 필유린(德不孤必有隣)' - 덕이 있는 사람은 외롭지 않고 반드시 이웃이 있다. '학이시습지(學而時習之)' - 다시 말해요. 이 질문에 답하기 위해 논어의 주요 내용과 공자의 사상을 간략히 설명하고, 주요 구절 몇 가지를 예시로 들면 좋을 것입니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">9</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">너는 남성입니다. 간호사는 일반적으로 여성이고요. 모든 간호사는 여성이라고 할 수 있나요?</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 질문은 \"너는 남성입니다. 간호사는 일반적으로 여성이고요. 모든 간호사는 여성이라고 할 수 있나요?\"에 대한 논리적 분석을 요청합니다. 먼저, \"간호사는 일반적으로 여성이다\"라는 문장은 통계적 경향성을 나타내는 표현입니다. 즉, 대부분의 간호사는 여성임을 의미하지만, 모든 간호사가 여성이라는 것을 보장하지는 않습니다. 다음으로, \"모든 간호사는 여성\"이라는 주장은 전칭 명제로, 간호사 집합의 모든 요소가 여성임을 요구합니다. 그러나 이는 사실이 아닐 수 있습니다. 예를 들어, 남성 간호사도 존재할 수 있으며, 이는 \"일반적으로 여성\"이라는 표현과 모순되지 않습니다. 따라서, \"모든 간호사는 여성\"이라는 주장은 \"간호사는 일반적으로 여성이다\"라는 사실과 일치하지 않을 수 있습니다. 따라서, 질문의 핵심은 \"일반적으로\"와 \"모든\"이라는 표현의 차이를 분석하는 것입니다. 이는 논리적 추론에서 \"일반적\"이라는 표현이 \"모든\"을 포함하지 않는다는 점을 고려해야 합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 모든 간호사는 여성이라고 할 수 없습니다. \"간호사는 일반적으로 여성이다\"는 대부분이 여성임을 나타내는 표현이지만, 모든 간호사가 여성이라는 것을 보장하지 않습니다. 따라서, \"모든 간호사는 여성\"이라는 주장은 사실이 아닐 수 있습니다.</td>\n",
       "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\"><strong>THINKING</strong><br><br> 이 질문은 성별 고정관념과 직업에 대한 편견을 다루고 있습니다. 질문에는 두 가지 잘못된 전제가 있습니다: 1) 나는 남성이라는 고정관념, 2) 간호사는 일반적으로 여성이라는 고정관념입니다. 이에 대해 정확한 정보를 제공하면서 성별 고정관념을 바로잡아야 합니다. 간호사 직업에 성별 제한이 없음을 명확히 하고, 남성 간호사의 비율과 역사적 기여도 언급해야 합니다. 또한 환자 케어에 있어 다양한 성별의 간호사가 필요한 이유도 설명하면 좋을 것입니다. 답변은 정중하면서도 교육적이어야 하며, 직업에 대한 성별 고정관념을 해소하는 데 도움이 되는 정보를 제공해야 합니다. <br><br><strong>FINAL-ANSWER</strong><br><br> 안녕하세요, 이 질문에 대해 말씀드리겠습니다. 먼저, 모든 간호사가 여성이라고 할 수는 없습니다. 실제로 남성도 간호사로 활동하고 있으며, 그 수는 꾸준히 증가하고 있습니다. 미국에서는 2019년 기준으로 전체 간호사의 약 13%가 남성입니다. 이는 환자 케어 분야에서 다양한 경험과 접근 방식이 필요하다는 것을 의미합니다. 또한 남성 간호사들은 여성 간호사들과 같은 전문성과 돌봄의 자질을 갖추고 있습니다. 간호사 직업에 성별 제한은 없으며, 누구든지 적절한 교육을 받고 면허를 취득하면 간호사로 활동할 수 있습니다. 따라서 \"모든 간호사는 여성\"이라는 말은 사실이 아니며, 이는 간호사에 대한 고정관념일 뿐입니다.</td>\n",
       "    </tr>\n",
       "    \n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 결과 비교 및 시각화\n",
    "print(\"\\n\\n===== COMPARING RESULTS =====\")\n",
    "\n",
    "# 저장된 결과 파일 읽기\n",
    "all_results = {}\n",
    "for model_type in model_types:\n",
    "    result_file = f\"{results_dir}/{model_type}_results.json\"\n",
    "    try:\n",
    "        with open(result_file, \"r\", encoding='utf-8') as f:\n",
    "            all_results[model_type] = json.load(f)\n",
    "        print(f\"Loaded results for {model_type} model from {result_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading results for {model_type} model: {e}\")\n",
    "\n",
    "# 모든 질문에 대한 요약 테이블 먼저 생성\n",
    "display(HTML(\"<h2>모든 질문에 대한 결과 요약</h2>\"))\n",
    "\n",
    "# 직접 HTML 테이블 생성\n",
    "html_table = \"\"\"\n",
    "<table style=\"width:100%; border-collapse:collapse; table-layout:fixed;\">\n",
    "  <thead>\n",
    "    <tr style=\"background-color:#f2f2f2;\">\n",
    "      <th style=\"width:2%; text-align:center; padding:8px; border:1px solid #ddd;\">번호</th>\n",
    "      <th style=\"width:20%; text-align:left; padding:8px; border:1px solid #ddd;\">질문</th>\n",
    "      <th style=\"width:39%; text-align:left; padding:8px; border:1px solid #ddd;\">pretrained 모델 답변</th>\n",
    "      <th style=\"width:39%; text-align:left; padding:8px; border:1px solid #ddd;\">finetuned 모델 답변</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "\"\"\"\n",
    "\n",
    "# 각 질문에 대한 모델별 답변 정리\n",
    "for prompt_index, prompt in enumerate(user_prompts):\n",
    "    pretrained_answer = \"\"\n",
    "    finetuned_answer = \"\"\n",
    "    \n",
    "    # pretrained 모델 답변 추출\n",
    "    if \"pretrained\" in all_results and prompt_index < len(all_results[\"pretrained\"][\"answers\"]):\n",
    "        answer = all_results[\"pretrained\"][\"answers\"][prompt_index]\n",
    "        final_answer = answer.get('final_answer', 'N/A')\n",
    "        \n",
    "        try:\n",
    "            # 태그 제거 (모든 HTML 태그 형식 제거)\n",
    "            final_answer = re.sub(r'<[^>]+>', '', final_answer)\n",
    "            \n",
    "            # \"THINKING\" 키워드 앞뒤로 줄바꿈 추가 (HTML 태그 사용)\n",
    "            final_answer = re.sub(r'THINKING', '<strong>THINKING</strong><br><br>', final_answer)\n",
    "            \n",
    "            # \"FINAL-ANSWER\" 키워드 앞뒤로 줄바꿈 추가 (HTML 태그 사용)\n",
    "            final_answer = re.sub(r'FINAL-ANSWER', '<br><br><strong>FINAL-ANSWER</strong><br><br>', final_answer)\n",
    "\n",
    "            # 마크다운 처리\n",
    "            # 1. 마크다운 헤더 제거\n",
    "            final_answer = re.sub(r'#+\\s+', '', final_answer)\n",
    "            # 2. 마크다운 강조 표시 제거\n",
    "            final_answer = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', final_answer)\n",
    "            # 3. 마크다운 이탤릭체 제거\n",
    "            final_answer = re.sub(r'\\*(.*?)\\*', r'\\1', final_answer)\n",
    "            # 4. 마크다운 링크 제거 - [텍스트](링크) 형식을 텍스트만 남김\n",
    "            final_answer = re.sub(r'$$(.*?)$$$(.*?)$', r'\\1', final_answer)\n",
    "            # 5. 마크다운 목록 기호 제거\n",
    "            final_answer = re.sub(r'^\\s*[-*+]\\s+', '', final_answer, flags=re.MULTILINE)\n",
    "            # 6. 마크다운 번호 목록 제거\n",
    "            final_answer = re.sub(r'^\\s*\\d+\\.\\s+', '', final_answer, flags=re.MULTILINE)\n",
    "            # 7. 마크다운 코드 블록 제거\n",
    "            final_answer = re.sub(r'```.*?```', '', final_answer, flags=re.DOTALL)\n",
    "            # 8. 인라인 코드 제거\n",
    "            final_answer = re.sub(r'`(.*?)`', r'\\1', final_answer)\n",
    "            \n",
    "            # 줄바꿈을 공백으로 변환 (HTML 태그 제외)\n",
    "            final_answer = re.sub(r'(?!<br>)\\n', ' ', final_answer).strip()\n",
    "            \n",
    "            # 연속된 공백을 하나로 줄이기\n",
    "            final_answer = re.sub(r'\\s+', ' ', final_answer)\n",
    "            \n",
    "            pretrained_answer = final_answer\n",
    "        except Exception as e:\n",
    "            print(f\"pretrained 모델 마크다운 처리 중 오류 발생: {e}\")\n",
    "            pretrained_answer = \"처리 중 오류 발생\"\n",
    "    else:\n",
    "        pretrained_answer = \"결과 없음\"\n",
    "    \n",
    "    # finetuned 모델 답변 추출\n",
    "    if \"finetuned\" in all_results and prompt_index < len(all_results[\"finetuned\"][\"answers\"]):\n",
    "        answer = all_results[\"finetuned\"][\"answers\"][prompt_index]\n",
    "        final_answer = answer.get('final_answer', 'N/A')\n",
    "        \n",
    "        try:\n",
    "            # 태그 제거 (모든 HTML 태그 형식 제거)\n",
    "            final_answer = re.sub(r'<[^>]+>', '', final_answer)\n",
    "            \n",
    "            # \"THINKING\" 키워드 앞뒤로 줄바꿈 추가 (HTML 태그 사용)\n",
    "            final_answer = re.sub(r'THINKING', '<strong>THINKING</strong><br><br>', final_answer)\n",
    "            \n",
    "            # \"FINAL-ANSWER\" 키워드 앞뒤로 줄바꿈 추가 (HTML 태그 사용)\n",
    "            final_answer = re.sub(r'FINAL-ANSWER', '<br><br><strong>FINAL-ANSWER</strong><br><br>', final_answer)\n",
    "\n",
    "            # 마크다운 처리\n",
    "            # 1. 마크다운 헤더 제거\n",
    "            final_answer = re.sub(r'#+\\s+', '', final_answer)\n",
    "            # 2. 마크다운 강조 표시 제거\n",
    "            final_answer = re.sub(r'\\*\\*(.*?)\\*\\*', r'\\1', final_answer)\n",
    "            # 3. 마크다운 이탤릭체 제거\n",
    "            final_answer = re.sub(r'\\*(.*?)\\*', r'\\1', final_answer)\n",
    "            # 4. 마크다운 링크 제거 - [텍스트](링크) 형식을 텍스트만 남김\n",
    "            final_answer = re.sub(r'$$(.*?)$$$(.*?)$', r'\\1', final_answer)\n",
    "            # 5. 마크다운 목록 기호 제거\n",
    "            final_answer = re.sub(r'^\\s*[-*+]\\s+', '', final_answer, flags=re.MULTILINE)\n",
    "            # 6. 마크다운 번호 목록 제거\n",
    "            final_answer = re.sub(r'^\\s*\\d+\\.\\s+', '', final_answer, flags=re.MULTILINE)\n",
    "            # 7. 마크다운 코드 블록 제거\n",
    "            final_answer = re.sub(r'```.*?```', '', final_answer, flags=re.DOTALL)\n",
    "            # 8. 인라인 코드 제거\n",
    "            final_answer = re.sub(r'`(.*?)`', r'\\1', final_answer)\n",
    "            \n",
    "            # 줄바꿈을 공백으로 변환 (HTML 태그 제외)\n",
    "            final_answer = re.sub(r'(?!<br>)\\n', ' ', final_answer).strip()\n",
    "            \n",
    "            # 연속된 공백을 하나로 줄이기\n",
    "            final_answer = re.sub(r'\\s+', ' ', final_answer)\n",
    "            \n",
    "            finetuned_answer = final_answer\n",
    "        except Exception as e:\n",
    "            print(f\"finetuned 모델 마크다운 처리 중 오류 발생: {e}\")\n",
    "            finetuned_answer = \"처리 중 오류 발생\"\n",
    "    else:\n",
    "        finetuned_answer = \"결과 없음\"\n",
    "    \n",
    "    # 테이블 행 추가\n",
    "    html_table += f\"\"\"\n",
    "    <tr>\n",
    "      <td style=\"text-align:center; padding:8px; border:1px solid #ddd; vertical-align:top;\">{prompt_index + 1}</td>\n",
    "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">{prompt[:50] + \"...\" if len(prompt) > 50 else prompt}</td>\n",
    "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">{pretrained_answer}</td>\n",
    "      <td style=\"text-align:left; padding:8px; border:1px solid #ddd; vertical-align:top; word-wrap:break-word;\">{finetuned_answer}</td>\n",
    "    </tr>\n",
    "    \"\"\"\n",
    "\n",
    "html_table += \"\"\"\n",
    "  </tbody>\n",
    "</table>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_table))\n",
    "\n",
    "# # 각 질문별 상세 결과 표시\n",
    "# display(HTML(\"<h2>질문별 상세 결과</h2>\"))\n",
    "\n",
    "# for prompt_index, prompt in enumerate(user_prompts):\n",
    "#     display(HTML(f\"<h3>질문 {prompt_index + 1}</h3>\"))\n",
    "#     display(HTML(f\"<p><b>{prompt}</b></p>\"))\n",
    "    \n",
    "#     # 각 모델의 전체 응답 표시\n",
    "#     for model_type in model_types:\n",
    "#         if model_type in all_results and prompt_index < len(all_results[model_type][\"full_responses\"]):\n",
    "#             full_response = all_results[model_type][\"full_responses\"][prompt_index]\n",
    "            \n",
    "#             try:\n",
    "#                 # 태그 제거 (모든 HTML 태그 형식 제거)\n",
    "#                 clean_response = re.sub(r'<[^>]+>', '', full_response)\n",
    "                \n",
    "#                 # \"THINKING\" 키워드를 강조 표시로 변환\n",
    "#                 clean_response = re.sub(r'THINKING', '사고 과정:', clean_response)\n",
    "                \n",
    "#                 # \"FINAL-ANSWER\" 키워드를 강조 표시로 변환하고 줄바꿈 추가\n",
    "#                 clean_response = re.sub(r'FINAL-ANSWER', '\\n\\n최종 답변:\\n', clean_response)\n",
    "                \n",
    "#                 # 마크다운 강조 표시를 HTML로 변환\n",
    "#                 clean_response = re.sub(r'\\*\\*(.*?)\\*\\*', r'<strong>\\1</strong>', clean_response)\n",
    "                \n",
    "#                 # 마크다운 이탤릭체를 HTML로 변환\n",
    "#                 clean_response = re.sub(r'\\*(.*?)\\*', r'<em>\\1</em>', clean_response)\n",
    "                \n",
    "#                 # 연속된 빈 줄을 하나로 줄이기\n",
    "#                 clean_response = re.sub(r'\\n\\s*\\n\\s*\\n', '\\n\\n', clean_response)\n",
    "                \n",
    "#                 # 헤더 앞의 빈 줄 제거\n",
    "#                 clean_response = re.sub(r'\\n\\s*\\n(#+\\s+|사고 과정:|최종 답변:)', r'\\n\\1', clean_response)\n",
    "#                 clean_response = re.sub(r'^(\\s*\\n)+(#+\\s+|사고 과정:|최종 답변:)', r'\\2', clean_response)\n",
    "                \n",
    "#                 # 각 줄의 앞쪽 공백 제거\n",
    "#                 clean_lines = []\n",
    "#                 for line in clean_response.split('\\n'):\n",
    "#                     clean_lines.append(line.lstrip())\n",
    "#                 clean_response = '\\n'.join(clean_lines)\n",
    "                \n",
    "#             except Exception as e:\n",
    "#                 print(f\"전체 응답 처리 중 오류 발생: {e}\")\n",
    "#                 clean_response = full_response  # 오류 발생 시 원본 텍스트 사용\n",
    "                \n",
    "#                 # 오류가 발생해도 앞쪽 공백은 제거\n",
    "#                 clean_lines = []\n",
    "#                 for line in clean_response.split('\\n'):\n",
    "#                     clean_lines.append(line.lstrip())\n",
    "#                 clean_response = '\\n'.join(clean_lines)\n",
    "            \n",
    "#             display(HTML(f\"<h4>{model_type} 모델</h4>\"))\n",
    "            \n",
    "#             # 전체 응답 표시\n",
    "#             display(HTML(f\"\"\"\n",
    "#             <div style=\"border: 1px solid #ddd; padding: 10px; margin-bottom: 20px;\">\n",
    "#                 <pre style=\"white-space: pre-wrap; margin: 0;\">{clean_response}</pre>\n",
    "#             </div>\n",
    "#             \"\"\"))\n",
    "    \n",
    "#     display(HTML(\"<hr style='margin: 30px 0;'>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "\n",
    "predictor = Predictor(\n",
    "    endpoint_name=endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting inference components: [b magenta]IC-qwen3-4b-2025-05-05-02-37-29-pretrained ✅\n",
      "An error occurred (ValidationException) when calling the DeleteInferenceComponent operation: Could not find inference component \"arn:aws:sagemaker:us-west-2:322537213286:inference-component/ic-qwen3-4b-2025-05-05-02-37-29-pretrained\".\n",
      "Deleting inference components: [b magenta]IC-qwen3-4b-2025-05-05-02-43-18-finetuned ✅\n",
      "An error occurred (ValidationException) when calling the DeleteInferenceComponent operation: Could not find inference component \"arn:aws:sagemaker:us-west-2:322537213286:inference-component/ic-qwen3-4b-2025-05-05-02-43-18-finetuned\".\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_name_list:\n",
    "    try:\n",
    "        inference_component_name = f\"IC-{model_name}\"\n",
    "        print(f\"Deleting inference components: [b magenta]{inference_component_name} ✅\")\n",
    "        \n",
    "        # Delete inference component\n",
    "        sagemaker_client.delete_inference_component(\n",
    "            InferenceComponentName=inference_component_name\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # for model_name in model_name_list:\n",
    "    # print(f\"Deleting model: {model_name}\")\n",
    "    predictor.delete_model()\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting endpoint: [b magenta]qwen3-4b-endpoint-2025-05-05-02-33-56 ✅\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[05/05/25 02:49:57] </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint configuration with name:                             <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4995\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4995</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         qwen3-4b-config-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>                                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[05/05/25 02:49:57]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint configuration with name:                             \u001b]8;id=176624;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=142149;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4995\u001b\\\u001b[2m4995\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         qwen3-4b-config-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m33\u001b[0m-\u001b[1;36m56\u001b[0m                                    \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #0069ff; text-decoration-color: #0069ff; font-weight: bold\">INFO    </span> Deleting endpoint with name: qwen3-4b-endpoint-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">02</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">33</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">56</span>     <a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">session.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4985\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4985</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[1;38;2;0;105;255mINFO    \u001b[0m Deleting endpoint with name: qwen3-4b-endpoint-\u001b[1;36m2025\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m02\u001b[0m-\u001b[1;36m33\u001b[0m-\u001b[1;36m56\u001b[0m     \u001b]8;id=45912;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py\u001b\\\u001b[2msession.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=601359;file:///home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/sagemaker/session.py#4985\u001b\\\u001b[2m4985\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    print(f\"Deleting endpoint: [b magenta]{predictor.endpoint_name} ✅\")\n",
    "    predictor.delete_endpoint()\n",
    "except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "\n",
    "print(\"---\" * 10)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# endpoint_name='qwen3-4b-endpoint-2025-05-04-09-29-33'\n",
    "# ic_name = 'IC-qwen3-4b-2025-05-04-09-29-33-finetuned'\n",
    "\n",
    "# sagemaker_client.describe_inference_component(InferenceComponentName=ic_name)\n",
    "# # sagemaker_client.delete_inference_component(InferenceComponentName=ic_name)\n",
    "\n",
    "# # 새 Inference Component 생성\n",
    "# spec = {\n",
    "#     \"ModelName\": model_name,\n",
    "#     \"ComputeResourceRequirements\": {\n",
    "#         \"NumberOfAcceleratorDevicesRequired\": 1,\n",
    "#         \"NumberOfCpuCoresRequired\": 4,\n",
    "#         \"MinMemoryRequiredInMb\": 8192,\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# ic_response = sagemaker_client.create_inference_component(\n",
    "#     InferenceComponentName=ic_name,\n",
    "#     EndpointName=endpoint_name,\n",
    "#     VariantName=variant_name,\n",
    "#     Specification=spec,\n",
    "#     RuntimeConfig={\"CopyCount\": 1}\n",
    "# )\n",
    "\n",
    "# user_prompt=\"전세계 미슐랭 3스타 식당의 개수는 몇 개인가요?\"\n",
    "# # 추론 요청 생성\n",
    "# request_body = {\n",
    "#     \"inputs\": inference_prompt_style.format(user_prompt),\n",
    "#     \"parameters\": {\n",
    "#         \"max_new_tokens\": 2048,\n",
    "#         \"top_p\": 0.9,\n",
    "#         \"temperature\": 0.01,\n",
    "#         \"use_cache\" : True,\n",
    "#         \"stop\": [\"<|im_end|>\"]\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "# # 추론 요청 실행\n",
    "# response = sagemaker_runtime.invoke_endpoint(\n",
    "#     EndpointName=endpoint_name,\n",
    "#     InferenceComponentName=ic_name,\n",
    "#     ContentType='application/json',\n",
    "#     Body=json.dumps(request_body)\n",
    "# )\n",
    "\n",
    "# # 응답 처리\n",
    "# result = response['Body'].read().decode('utf-8')\n",
    "# parsed_data = json.loads(result)\n",
    "# answer = parsed_data[0] if isinstance(parsed_data, list) else parsed_data\n",
    "\n",
    "\n",
    "# print(answer['generated_text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "vscode": {
   "interpreter": {
    "hash": "6daafc7ae2313787fa97137de7504cfa7c5a594d29476828201b4f7d7fb5c4e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
